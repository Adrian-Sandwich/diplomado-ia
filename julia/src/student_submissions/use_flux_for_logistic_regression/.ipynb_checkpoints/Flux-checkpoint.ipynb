{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350ffdea-0eb4-4062-b1c2-e8ca64aa61c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: categorical not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: categorical not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:21"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas en one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, DataFrame(Matrix(onehot(df.Geography))))\n",
    "df_onehot = hcat(df_onehot, DataFrame(Matrix(onehot(df.Gender))))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "data = DataLoader((X_train', y_train'), batchsize = 32, shuffle = true)\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n",
    "\n",
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n",
    "\n",
    "# Fin del código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080b77ac-b8a4-493b-81ad-6318368a0d95",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: onehot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: onehot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:25"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "using CategoricalArrays  # Para trabajar con datos categóricos\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas en one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, DataFrame(Matrix(onehot(df.Geography))))\n",
    "df_onehot = hcat(df_onehot, DataFrame(Matrix(onehot(df.Gender))))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "data = DataLoader((X_train', y_train'), batchsize = 32, shuffle = true)\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n",
    "\n",
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a476b3d6-5dd0-4086-9743-60c779eb1702",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching DataFrame(::Matrix{Bool}; names=String7[\"France\", \"Germany\", \"Spain\"])\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::Matrix) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:400\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  DataFrame(::AbstractMatrix, \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:377\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  DataFrame(::AbstractMatrix, \u001b[91m::AbstractVector\u001b[39m; makeunique, copycols) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:385\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DataFrame(::Matrix{Bool}; names=String7[\"France\", \"Germany\", \"Spain\"])\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::Matrix) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:400\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  DataFrame(::AbstractMatrix, \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:377\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  DataFrame(::AbstractMatrix, \u001b[91m::AbstractVector\u001b[39m; makeunique, copycols) at ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:385\u001b[91m got unsupported keyword argument \"names\"\u001b[39m\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] kwerr(::NamedTuple{(:names,), Tuple{Vector{String7}}}, ::Type, ::Matrix{Bool})",
      "   @ Base ./error.jl:165",
      " [2] onehot_encode(column::CategoricalVector{String7, UInt32, String7, CategoricalValue{String7, UInt32}, Union{}})",
      "   @ Main ./In[3]:29",
      " [3] top-level scope",
      "   @ In[3]:34"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "using CategoricalArrays\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas a one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "\n",
    "# Función para codificación one-hot con Flux\n",
    "function onehot_encode(column)\n",
    "    categories = levels(column)\n",
    "    onehot_matrix = Flux.onehotbatch(column, categories)\n",
    "    return DataFrame(Matrix(onehot_matrix), names=categories)\n",
    "end\n",
    "\n",
    "# Aplicar one-hot encoding a las columnas categóricas\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Geography))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Gender))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "data = DataLoader((X_train', y_train'), batchsize = 32, shuffle = true)\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n",
    "\n",
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea18349c-8137-4119-88a7-f9c2867fa182",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: Number of columns (10000) and number of column names (3) are not equal",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: Number of columns (10000) and number of column names (3) are not equal",
      "",
      "Stacktrace:",
      " [1] DataFrame(columns::Vector{AbstractVector}, colindex::DataFrames.Index; copycols::Bool)",
      "   @ DataFrames ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:198",
      " [2] DataFrame(columns::Vector{AbstractVector}, cnames::Vector{Symbol}; makeunique::Bool, copycols::Bool)",
      "   @ DataFrames ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:358",
      " [3] DataFrame(columns::Matrix{Bool}, cnames::Vector{Symbol}; makeunique::Bool, copycols::Bool)",
      "   @ DataFrames ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:380",
      " [4] DataFrame",
      "   @ ~/.julia/packages/DataFrames/kcA9R/src/dataframe/dataframe.jl:377 [inlined]",
      " [5] onehot_encode(column::CategoricalVector{String7, UInt32, String7, CategoricalValue{String7, UInt32}, Union{}})",
      "   @ Main ./In[4]:30",
      " [6] top-level scope",
      "   @ In[4]:35"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "using CategoricalArrays\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas a one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "\n",
    "# Función para codificación one-hot con Flux\n",
    "function onehot_encode(column)\n",
    "    categories = levels(column)\n",
    "    onehot_matrix = Flux.onehotbatch(column, categories)\n",
    "    # Crear DataFrame con nombres de columnas correctos\n",
    "    return DataFrame(Matrix(onehot_matrix), Symbol.(categories))\n",
    "end\n",
    "\n",
    "# Aplicar one-hot encoding a las columnas categóricas\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Geography))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Gender))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "data = DataLoader((X_train', y_train'), batchsize = 32, shuffle = true)\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n",
    "\n",
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f134d85-ad85-48fd-88c0-34d097527226",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: DataLoader not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: DataLoader not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[5]:64"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "using CategoricalArrays\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas a one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "\n",
    "# Función para codificación one-hot con Flux\n",
    "function onehot_encode(column)\n",
    "    categories = levels(column)\n",
    "    onehot_matrix = Flux.onehotbatch(column, categories)  # Matriz transpuesta\n",
    "    # Crear DataFrame con categorías como nombres de columnas\n",
    "    return DataFrame(onehot_matrix', Symbol.(categories))  # Transponer para coincidir\n",
    "end\n",
    "\n",
    "# Aplicar one-hot encoding a las columnas categóricas\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Geography))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Gender))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "data = DataLoader((X_train', y_train'), batchsize = 32, shuffle = true)\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(model), data, opt)\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n",
    "\n",
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88969611-1909-45c3-8936-c076ecf784d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: glorot_uniform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: glorot_uniform not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[39]:55"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Flux\n",
    "using StatsBase\n",
    "using MLDataUtils\n",
    "using ROCAnalysis\n",
    "using Plots\n",
    "using CategoricalArrays\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "file_path = \"Churn_Modelling.csv\"  # Cambia esto a la ruta donde está tu archivo\n",
    "df = CSV.read(file_path, DataFrame)\n",
    "\n",
    "# Paso 2: Preprocesamiento\n",
    "# Seleccionar las columnas relevantes\n",
    "selected_columns = [:CreditScore, :Geography, :Gender, :Age, :Tenure, :Balance, \n",
    "                    :NumOfProducts, :HasCrCard, :IsActiveMember, :EstimatedSalary, :Exited]\n",
    "df = df[:, selected_columns]\n",
    "\n",
    "# Convertir variables categóricas a one-hot encoding\n",
    "df.Geography = categorical(df.Geography)\n",
    "df.Gender = categorical(df.Gender)\n",
    "\n",
    "# Función para codificación one-hot con Flux\n",
    "function onehot_encode(column)\n",
    "    categories = levels(column)\n",
    "    onehot_matrix = Flux.onehotbatch(column, categories)  # Matriz transpuesta\n",
    "    # Crear DataFrame con categorías como nombres de columnas\n",
    "    return DataFrame(onehot_matrix', Symbol.(categories))  # Transponer para coincidir\n",
    "end\n",
    "\n",
    "# Aplicar one-hot encoding a las columnas categóricas\n",
    "df_onehot = select(df, Not([:Geography, :Gender]))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Geography))\n",
    "df_onehot = hcat(df_onehot, onehot_encode(df.Gender))\n",
    "\n",
    "# Normalizar las columnas numéricas\n",
    "numerical_cols = names(df_onehot, eltype(Float64))\n",
    "for col in numerical_cols\n",
    "    df_onehot[:, col] = zscore(df_onehot[:, col])\n",
    "end\n",
    "\n",
    "# Dividir datos en X (características) e y (etiquetas)\n",
    "X = Matrix(select(df_onehot, Not(:Exited)))\n",
    "y = Matrix(select(df_onehot, :Exited))\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "train_indices, test_indices = splitobs(1:size(X, 1), at = 0.8)  # 80% entrenamiento, 20% prueba\n",
    "X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
    "y_train, y_test = y[train_indices, :], y[test_indices, :]\n",
    "\n",
    "# Paso 3: Definir y entrenar el modelo\n",
    "# Modelo de regresión logística\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 2), 1, σ, init = glorot_uniform)  # 1 salida con función de activación sigmoide\n",
    ")\n",
    "\n",
    "# Función de pérdida (Binary Cross-Entropy) y optimizador\n",
    "loss(x, y) = Flux.logitbinarycrossentropy(model(x), y)\n",
    "opt = Flux.Descent(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83460faf-146f-4d26-8348-9d97611f5e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>10×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">CreditScore</th><th style = \"text-align: left;\">Age</th><th style = \"text-align: left;\">Tenure</th><th style = \"text-align: left;\">Balance</th><th style = \"text-align: left;\">NumOfProducts</th><th style = \"text-align: left;\">HasCrCard</th><th style = \"text-align: left;\">IsActiveMember</th><th style = \"text-align: left;\">EstimatedSalary</th><th style = \"text-align: left;\">Exited</th><th style = \"text-align: left;\">France</th><th style = \"text-align: left;\">Germany</th><th style = \"text-align: left;\">Spain</th><th style = \"text-align: left;\">Female</th><th style = \"text-align: left;\">Male</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">619</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-1.22579</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.0218854</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">608</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.117344</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.216523</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">502</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">1.33299</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.240675</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">699</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-1.22579</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">-0.108912</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">850</td><td style = \"text-align: right;\">43</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0.785689</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.365258</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">645</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">0.597299</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.863607</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">822</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">-1.22579</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-1.56541</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">376</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0.617988</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.334837</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">501</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">1.05077</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.437307</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">684</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0.931417</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.493206</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">true</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& CreditScore & Age & Tenure & Balance & NumOfProducts & HasCrCard & IsActiveMember & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Float64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 619 & 42 & 2 & -1.22579 & 1 & 1 & 1 & $\\dots$ \\\\\n",
       "\t2 & 608 & 41 & 1 & 0.117344 & 1 & 0 & 1 & $\\dots$ \\\\\n",
       "\t3 & 502 & 42 & 8 & 1.33299 & 3 & 1 & 0 & $\\dots$ \\\\\n",
       "\t4 & 699 & 39 & 1 & -1.22579 & 2 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 850 & 43 & 2 & 0.785689 & 1 & 1 & 1 & $\\dots$ \\\\\n",
       "\t6 & 645 & 44 & 8 & 0.597299 & 2 & 1 & 0 & $\\dots$ \\\\\n",
       "\t7 & 822 & 50 & 7 & -1.22579 & 2 & 1 & 1 & $\\dots$ \\\\\n",
       "\t8 & 376 & 29 & 4 & 0.617988 & 4 & 1 & 0 & $\\dots$ \\\\\n",
       "\t9 & 501 & 44 & 4 & 1.05077 & 2 & 0 & 1 & $\\dots$ \\\\\n",
       "\t10 & 684 & 27 & 2 & 0.931417 & 1 & 1 & 1 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m10×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m CreditScore \u001b[0m\u001b[1m Age   \u001b[0m\u001b[1m Tenure \u001b[0m\u001b[1m Balance   \u001b[0m\u001b[1m NumOfProducts \u001b[0m\u001b[1m HasCrCard \u001b[0m\u001b[1m IsActi\u001b[0m ⋯\n",
       "     │\u001b[90m Int64       \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64         \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64 \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │         619     42       2  -1.22579               1          1         ⋯\n",
       "   2 │         608     41       1   0.117344              1          0\n",
       "   3 │         502     42       8   1.33299               3          1\n",
       "   4 │         699     39       1  -1.22579               2          0\n",
       "   5 │         850     43       2   0.785689              1          1         ⋯\n",
       "   6 │         645     44       8   0.597299              2          1\n",
       "   7 │         822     50       7  -1.22579               2          1\n",
       "   8 │         376     29       4   0.617988              4          1\n",
       "   9 │         501     44       4   1.05077               2          0         ⋯\n",
       "  10 │         684     27       2   0.931417              1          1\n",
       "\u001b[36m                                                               8 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(df_onehot, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e034c6-a3e0-425d-a4d7-10d3557611f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
      "\u001b[32m⌃\u001b[39m\u001b[90m [9920b226] \u001b[39m\u001b[92m+ MLDataPattern v0.5.4\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.8/Manifest.toml`\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 8000×13 Matrix{Float64} at index [1:8000, 1:32]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 8000×13 Matrix{Float64} at index [1:8000, 1:32]",
      "",
      "Stacktrace:",
      " [1] throw_boundserror(A::Matrix{Float64}, I::Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}})",
      "   @ Base ./abstractarray.jl:703",
      " [2] checkbounds",
      "   @ ./abstractarray.jl:668 [inlined]",
      " [3] _getindex",
      "   @ ./multidimensional.jl:874 [inlined]",
      " [4] getindex(::Matrix{Float64}, ::Function, ::UnitRange{Int64})",
      "   @ Base ./abstractarray.jl:1241",
      " [5] (::var\"#1#2\")(i::Int64)",
      "   @ Main ./none:0",
      " [6] iterate",
      "   @ ./generator.jl:47 [inlined]",
      " [7] collect(itr::Base.Generator{StepRange{Int64, Int64}, var\"#1#2\"})",
      "   @ Base ./array.jl:787",
      " [8] top-level scope",
      "   @ In[7]:7"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"MLDataPattern\")\n",
    "\n",
    "using MLDataPattern\n",
    "\n",
    "# Crear lotes manualmente\n",
    "train_batches = [(X_train[:, i:i+31], y_train[:, i:i+31]) for i in 1:32:size(X_train, 2)]\n",
    "\n",
    "for epoch in 1:100\n",
    "    for (x_batch, y_batch) in train_batches\n",
    "        Flux.train!(loss, params(model), [(x_batch, y_batch)], opt)\n",
    "    end\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ee381f-6d11-408a-b61c-c96e7d08c652",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: params not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: params not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[9]:14"
     ]
    }
   ],
   "source": [
    "# Función para crear lotes manuales\n",
    "function create_batches(X, y, batch_size)\n",
    "    n = size(X, 2)  # Número de columnas (ejemplos)\n",
    "    batches = [(X[:, i:min(i+batch_size-1, n)], y[:, i:min(i+batch_size-1, n)]) for i in 1:batch_size:n]\n",
    "    return batches\n",
    "end\n",
    "\n",
    "# Crear lotes\n",
    "train_batches = create_batches(X_train', y_train', 32)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in 1:100\n",
    "    for (x_batch, y_batch) in train_batches\n",
    "        Flux.train!(loss, params(model), [(x_batch, y_batch)], opt)\n",
    "    end\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "979fdeab-fc3d-489f-8c9c-d63870d4cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1073862\n",
      "Epoch 2, Loss: 1.1073862\n",
      "Epoch 3, Loss: 1.1073862\n",
      "Epoch 4, Loss: 1.1073862\n",
      "Epoch 5, Loss: 1.1073862\n",
      "Epoch 6, Loss: 1.1073862\n",
      "Epoch 7, Loss: 1.1073862\n",
      "Epoch 8, Loss: 1.1073862\n",
      "Epoch 9, Loss: 1.1073862\n",
      "Epoch 10, Loss: 1.1073862\n",
      "Epoch 11, Loss: 1.1073862\n",
      "Epoch 12, Loss: 1.1073862\n",
      "Epoch 13, Loss: 1.1073862\n",
      "Epoch 14, Loss: 1.1073862\n",
      "Epoch 15, Loss: 1.1073862\n",
      "Epoch 16, Loss: 1.1073862\n",
      "Epoch 17, Loss: 1.1073862\n",
      "Epoch 18, Loss: 1.1073862\n",
      "Epoch 19, Loss: 1.1073862\n",
      "Epoch 20, Loss: 1.1073862\n",
      "Epoch 21, Loss: 1.1073862\n",
      "Epoch 22, Loss: 1.1073862\n",
      "Epoch 23, Loss: 1.1073862\n",
      "Epoch 24, Loss: 1.1073862\n",
      "Epoch 25, Loss: 1.1073862\n",
      "Epoch 26, Loss: 1.1073862\n",
      "Epoch 27, Loss: 1.1073862\n",
      "Epoch 28, Loss: 1.1073862\n",
      "Epoch 29, Loss: 1.1073862\n",
      "Epoch 30, Loss: 1.1073862\n",
      "Epoch 31, Loss: 1.1073862\n",
      "Epoch 32, Loss: 1.1073862\n",
      "Epoch 33, Loss: 1.1073862\n",
      "Epoch 34, Loss: 1.1073862\n",
      "Epoch 35, Loss: 1.1073862\n",
      "Epoch 36, Loss: 1.1073862\n",
      "Epoch 37, Loss: 1.1073862\n",
      "Epoch 38, Loss: 1.1073862\n",
      "Epoch 39, Loss: 1.1073862\n",
      "Epoch 40, Loss: 1.1073862\n",
      "Epoch 41, Loss: 1.1073862\n",
      "Epoch 42, Loss: 1.1073862\n",
      "Epoch 43, Loss: 1.1073862\n",
      "Epoch 44, Loss: 1.1073862\n",
      "Epoch 45, Loss: 1.1073862\n",
      "Epoch 46, Loss: 1.1073862\n",
      "Epoch 47, Loss: 1.1073862\n",
      "Epoch 48, Loss: 1.1073862\n",
      "Epoch 49, Loss: 1.1073862\n",
      "Epoch 50, Loss: 1.1073862\n",
      "Epoch 51, Loss: 1.1073862\n",
      "Epoch 52, Loss: 1.1073862\n",
      "Epoch 53, Loss: 1.1073862\n",
      "Epoch 54, Loss: 1.1073862\n",
      "Epoch 55, Loss: 1.1073862\n",
      "Epoch 56, Loss: 1.1073862\n",
      "Epoch 57, Loss: 1.1073862\n",
      "Epoch 58, Loss: 1.1073862\n",
      "Epoch 59, Loss: 1.1073862\n",
      "Epoch 60, Loss: 1.1073862\n",
      "Epoch 61, Loss: 1.1073862\n",
      "Epoch 62, Loss: 1.1073862\n",
      "Epoch 63, Loss: 1.1073862\n",
      "Epoch 64, Loss: 1.1073862\n",
      "Epoch 65, Loss: 1.1073862\n",
      "Epoch 66, Loss: 1.1073862\n",
      "Epoch 67, Loss: 1.1073862\n",
      "Epoch 68, Loss: 1.1073862\n",
      "Epoch 69, Loss: 1.1073862\n",
      "Epoch 70, Loss: 1.1073862\n",
      "Epoch 71, Loss: 1.1073862\n",
      "Epoch 72, Loss: 1.1073862\n",
      "Epoch 73, Loss: 1.1073862\n",
      "Epoch 74, Loss: 1.1073862\n",
      "Epoch 75, Loss: 1.1073862\n",
      "Epoch 76, Loss: 1.1073862\n",
      "Epoch 77, Loss: 1.1073862\n",
      "Epoch 78, Loss: 1.1073862\n",
      "Epoch 79, Loss: 1.1073862\n",
      "Epoch 80, Loss: 1.1073862\n",
      "Epoch 81, Loss: 1.1073862\n",
      "Epoch 82, Loss: 1.1073862\n",
      "Epoch 83, Loss: 1.1073862\n",
      "Epoch 84, Loss: 1.1073862\n",
      "Epoch 85, Loss: 1.1073862\n",
      "Epoch 86, Loss: 1.1073862\n",
      "Epoch 87, Loss: 1.1073862\n",
      "Epoch 88, Loss: 1.1073862\n",
      "Epoch 89, Loss: 1.1073862\n",
      "Epoch 90, Loss: 1.1073862\n",
      "Epoch 91, Loss: 1.1073862\n",
      "Epoch 92, Loss: 1.1073862\n",
      "Epoch 93, Loss: 1.1073862\n",
      "Epoch 94, Loss: 1.1073862\n",
      "Epoch 95, Loss: 1.1073862\n",
      "Epoch 96, Loss: 1.1073862\n",
      "Epoch 97, Loss: 1.1073862\n",
      "Epoch 98, Loss: 1.1073862\n",
      "Epoch 99, Loss: 1.1073862\n",
      "Epoch 100, Loss: 1.1073862\n"
     ]
    }
   ],
   "source": [
    "using MLDataPattern\n",
    "\n",
    "# Crear lotes con índices válidos\n",
    "train_batches = [(X_train[:, i:min(i + 31, size(X_train, 2))], \n",
    "                  y_train[:, i:min(i + 31, size(y_train, 2))]) \n",
    "                 for i in 1:32:size(X_train, 2)]\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in 1:100\n",
    "    for (x_batch, y_batch) in train_batches\n",
    "        Flux.train!(loss, Flux.params(model), [(x_batch', y_batch')], opt)\n",
    "    end\n",
    "    println(\"Epoch $epoch, Loss: $(loss(X_train', y_train'))\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bca886f-7935-4d3b-bb37-3c863bd68de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: confusion_matrix not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: confusion_matrix not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:7"
     ]
    }
   ],
   "source": [
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "roc = roc_curve(y_test', model(X_test')[:])\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f65eb8-5019-4ead-a8a8-866130c5accc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confusion_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function confusion_matrix(y_true, y_pred)\n",
    "    # Asegurar que las entradas sean vectores booleanos\n",
    "    tp = sum((y_true .== 1) .& (y_pred .== 1))  # Verdaderos positivos\n",
    "    tn = sum((y_true .== 0) .& (y_pred .== 0))  # Verdaderos negativos\n",
    "    fp = sum((y_true .== 0) .& (y_pred .== 1))  # Falsos positivos\n",
    "    fn = sum((y_true .== 1) .& (y_pred .== 0))  # Falsos negativos\n",
    "    return [tp fp; fn tn]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d376153-4cb3-4648-a5f6-10dac8b9a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      "[0 0; 1647 6353]\n",
      "Testing Confusion Matrix:\n",
      "[0 0; 390 1610]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: roc_curve not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: roc_curve not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[14]:15"
     ]
    }
   ],
   "source": [
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Curva ROC\n",
    "using ROCAnalysis\n",
    "\n",
    "roc = roc_curve(y_test', vec(model(X_test')))\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "using Plots\n",
    "\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105f95af-ab14-467a-afda-70e3dfcb8668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      "[0 0; 1647 6353]\n",
      "Testing Confusion Matrix:\n",
      "[0 0; 390 1610]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: roc_curve not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: roc_curve not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:14"
     ]
    }
   ],
   "source": [
    "# Paso 4: Evaluar el modelo\n",
    "# Predicciones\n",
    "y_pred_train = model(X_train') .> 0.5\n",
    "y_pred_test = model(X_test') .> 0.5\n",
    "\n",
    "# Matriz de confusión\n",
    "train_cm = confusion_matrix(y_train', y_pred_train)\n",
    "test_cm = confusion_matrix(y_test', y_pred_test)\n",
    "println(\"Training Confusion Matrix:\\n\", train_cm)\n",
    "println(\"Testing Confusion Matrix:\\n\", test_cm)\n",
    "\n",
    "# Calcular la curva ROC y el AUC\n",
    "# Las etiquetas reales deben ser un vector y las probabilidades predichas también\n",
    "roc = roc_curve(y_test', vec(model(X_test')))\n",
    "auc_value = auc(roc)\n",
    "println(\"AUC: $auc_value\")\n",
    "\n",
    "# Graficar la curva ROC\n",
    "using Plots\n",
    "plot(roc, title = \"ROC Curve\", xlabel = \"False Positive Rate\", ylabel = \"True Positive Rate\", legend = false)\n",
    "savefig(\"roc_curve.png\")  # Opcional: guardar la curva ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69f44d-77d9-4c02-8d35-8554bf264663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
