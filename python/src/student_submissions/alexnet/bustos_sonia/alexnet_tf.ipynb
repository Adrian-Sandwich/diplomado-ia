{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oBpIvHRdrPX",
        "outputId": "ffbfcaf6-0f02-4857-961e-cb869faa02ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 63ms/step - accuracy: 0.2765 - loss: 1.9224 - val_accuracy: 0.4423 - val_loss: 1.4787 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.5001 - loss: 1.3797 - val_accuracy: 0.5745 - val_loss: 1.1926 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.5652 - loss: 1.2280 - val_accuracy: 0.6165 - val_loss: 1.0821 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - accuracy: 0.5942 - loss: 1.1485 - val_accuracy: 0.6376 - val_loss: 1.0151 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.6207 - loss: 1.0872 - val_accuracy: 0.6330 - val_loss: 1.1067 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - accuracy: 0.6424 - loss: 1.0316 - val_accuracy: 0.6556 - val_loss: 0.9893 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.6498 - loss: 1.0008 - val_accuracy: 0.6857 - val_loss: 0.9211 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.6592 - loss: 0.9873 - val_accuracy: 0.6723 - val_loss: 0.9517 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.6702 - loss: 0.9533 - val_accuracy: 0.6681 - val_loss: 1.0073 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6676 - loss: 0.9598\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.6676 - loss: 0.9598 - val_accuracy: 0.6795 - val_loss: 0.9364 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "313/313 - 2s - 8ms/step - accuracy: 0.6857 - loss: 0.9211\n",
            "Test Accuracy: 0.6857\n",
            "Collecting tf-keras-vis\n",
            "  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis) (1.13.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis) (11.1.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis) (1.2.18)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis) (2.37.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis) (24.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->tf-keras-vis) (1.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio->tf-keras-vis) (1.26.4)\n",
            "Downloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-keras-vis\n",
            "Successfully installed tf-keras-vis-0.8.7\n"
          ]
        }
      ],
      "source": [
        "# Importaciones necesarias para construir y entrenar redes neuronales con TensorFlow/Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models  # Crear modelos y capas\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Aumentación de datos\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  # Callbacks para mejorar el entrenamiento\n",
        "from tensorflow.keras.optimizers import Adam  # Optimizador Adam\n",
        "import numpy as np  # Operaciones matemáticas y manejo de datos\n",
        "import matplotlib.pyplot as plt  # Visualización de gráficos\n",
        "from tensorflow.keras.datasets import cifar10  # Conjunto de datos CIFAR-10\n",
        "\n",
        "# **1. Cargar y preprocesar los datos de CIFAR-10**\n",
        "# CIFAR-10 contiene imágenes (32x32) divididas en 10 clases\n",
        "# Aumentación de datos para enriquecer el conjunto de entrenamiento\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=15,        # Rotación aleatoria de hasta 15 grados\n",
        "    width_shift_range=0.1,    # Desplazamiento horizontal aleatorio del 10% del ancho\n",
        "    height_shift_range=0.1,   # Desplazamiento vertical aleatorio del 10% de la altura\n",
        "    horizontal_flip=True      # Volteo horizontal aleatorio\n",
        ")\n",
        "\n",
        "# Cargar los datos de entrenamiento y prueba\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Convertir las etiquetas numéricas a formato one-hot encoding (necesario para clasificación multiclase)\n",
        "y_train, y_test = tf.keras.utils.to_categorical(y_train, 10), tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# **2. Normalización de datos**\n",
        "# Normaliza las imágenes con respecto al promedio y la desviación estándar (simulando la preparación de datos de ImageNet)\n",
        "mean = np.mean(x_train, axis=(0,1,2)) / 255.0  # Promedio de los valores de píxeles\n",
        "std = np.std(x_train, axis=(0,1,2)) / 255.0    # Desviación estándar de los valores de píxeles\n",
        "x_train = (x_train / 255.0 - mean) / std       # Normaliza el conjunto de entrenamiento\n",
        "x_test = (x_test / 255.0 - mean) / std         # Normaliza el conjunto de prueba\n",
        "\n",
        "# Define la forma de entrada (32x32 imágenes RGB)\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# **3. Definir el modelo AlexNet desde cero**\n",
        "def alexnet():\n",
        "    # Se utiliza un modelo secuencial donde las capas se apilan linealmente\n",
        "    model = models.Sequential([\n",
        "        # Primera capa convolucional con 96 filtros, kernel 3x3 y activación ReLU\n",
        "        layers.Conv2D(96, (3, 3), strides=1, activation='relu', input_shape=input_shape, padding='same'),\n",
        "        # MaxPooling reduce las dimensiones espaciales\n",
        "        layers.MaxPooling2D((3, 3), strides=2, padding='same'),\n",
        "\n",
        "        # Segunda capa convolucional con kernel 5x5 y 256 filtros\n",
        "        layers.Conv2D(256, (5, 5), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((3, 3), strides=2, padding='same'),\n",
        "\n",
        "        # Tres capas convolucionales consecutivas\n",
        "        layers.Conv2D(384, (3, 3), activation='relu', padding='same'),\n",
        "        layers.Conv2D(384, (3, 3), activation='relu', padding='same'),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((3, 3), strides=2, padding='same'),\n",
        "\n",
        "        # Aplanar la salida de las capas convolucionales para conectarlas con las densas\n",
        "        layers.Flatten(),\n",
        "\n",
        "        # Primera capa densa con 4096 neuronas\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dropout(0.5),  # Dropout para evitar sobreajuste\n",
        "\n",
        "        # Segunda capa densa con 4096 neuronas\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        # Capa de salida para clasificar en 10 clases (softmax para clasificación multiclase)\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# **4. Compilar el modelo**\n",
        "model = alexnet()\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),  # Optimizador Adam con tasa de aprendizaje inicial 0.001\n",
        "              loss='categorical_crossentropy',      # Función de pérdida para clasificación multiclase\n",
        "              metrics=['accuracy'])                # Métrica de precisión para el monitoreo\n",
        "\n",
        "# **5. Configurar callbacks para el entrenamiento**\n",
        "callbacks = [\n",
        "    # Reduce la tasa de aprendizaje si no mejora la pérdida en 3 épocas consecutivas\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    # Detiene el entrenamiento si no hay mejora en 7 épocas consecutivas\n",
        "    EarlyStopping(monitor='val_loss', patience=7, verbose=1, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# **6. Entrenar el modelo con aumentación de datos**\n",
        "history = model.fit(\n",
        "    data_augmentation.flow(x_train, y_train, batch_size=64),  # Genera lotes con aumentación\n",
        "    epochs=10,                                               # Entrena durante 10 épocas\n",
        "    validation_data=(x_test, y_test),                        # Datos de validación\n",
        "    callbacks=callbacks                                      # Aplica los callbacks\n",
        ")\n",
        "\n",
        "# **7. Evaluar el modelo**\n",
        "# Evalúa el modelo final en el conjunto de prueba\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")  # Imprime la precisión final #7 min\n",
        "\n",
        "# **8. Instalar tf-keras-vis para visualización de activaciones**\n",
        "!pip install tf-keras-vis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxw8XEt9e6Uc",
        "outputId": "f6baed2d-7a6a-4263-e750-c59cf6edd150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "782/782 - 366s - 468ms/step - accuracy: 0.5521 - loss: 2.4002 - val_accuracy: 0.7436 - val_loss: 0.8576\n",
            "Epoch 2/10\n",
            "782/782 - 328s - 419ms/step - accuracy: 0.6081 - loss: 1.3132 - val_accuracy: 0.7605 - val_loss: 0.8028\n",
            "Epoch 3/10\n",
            "782/782 - 325s - 415ms/step - accuracy: 0.6480 - loss: 1.1766 - val_accuracy: 0.7764 - val_loss: 0.7245\n",
            "Epoch 4/10\n",
            "782/782 - 293s - 374ms/step - accuracy: 0.6734 - loss: 1.0891 - val_accuracy: 0.7971 - val_loss: 0.6634\n",
            "Epoch 5/10\n",
            "782/782 - 354s - 453ms/step - accuracy: 0.6947 - loss: 1.0027 - val_accuracy: 0.8143 - val_loss: 0.6096\n",
            "Epoch 6/10\n",
            "782/782 - 328s - 419ms/step - accuracy: 0.7136 - loss: 0.9355 - val_accuracy: 0.8029 - val_loss: 0.6300\n",
            "Epoch 7/10\n",
            "782/782 - 323s - 413ms/step - accuracy: 0.7165 - loss: 0.9137 - val_accuracy: 0.8204 - val_loss: 0.5945\n",
            "Epoch 8/10\n",
            "782/782 - 327s - 419ms/step - accuracy: 0.7248 - loss: 0.8946 - val_accuracy: 0.8244 - val_loss: 0.5785\n",
            "Epoch 9/10\n",
            "782/782 - 328s - 419ms/step - accuracy: 0.7347 - loss: 0.8689 - val_accuracy: 0.8243 - val_loss: 0.5818\n",
            "Epoch 10/10\n",
            "782/782 - 328s - 419ms/step - accuracy: 0.7350 - loss: 0.8734 - val_accuracy: 0.8215 - val_loss: 0.5760\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical  # Conversión de etiquetas a formato one-hot\n",
        "\n",
        "# **1. Cargar y preprocesar los datos de CIFAR-10**\n",
        "# CIFAR-10 contiene imágenes de 32x32 píxeles, divididas en 10 clases\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Convertir las etiquetas de formato numérico a one-hot encoding (necesario para clasificación multiclase)\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "# **2. Configurar Data Augmentation (Aumentación de datos)**\n",
        "# Esto enriquece el conjunto de entrenamiento mediante transformaciones aleatorias para mejorar la generalización\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,         # Rotar imágenes aleatoriamente hasta 15 grados\n",
        "    width_shift_range=0.1,     # Desplazamiento horizontal aleatorio del 10% del ancho\n",
        "    height_shift_range=0.1,    # Desplazamiento vertical aleatorio del 10% de la altura\n",
        "    horizontal_flip=True       # Volteo horizontal aleatorio\n",
        ")\n",
        "\n",
        "# Ajustar el generador de datos al conjunto de entrenamiento\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# **3. Descargar el modelo AlexNet preentrenado**\n",
        "# Nota: TensorFlow no incluye AlexNet por defecto, por lo que se utiliza VGG16 como alternativa\n",
        "alexnet_tf = tf.keras.applications.VGG16(\n",
        "    weights=\"imagenet\",         # Usar pesos preentrenados en el conjunto de datos ImageNet\n",
        "    include_top=False,          # Excluir las capas densas originales (solo usar la parte convolucional)\n",
        "    input_shape=(224, 224, 3)   # Cambiar la entrada para que coincida con ImageNet (224x224, 3 canales RGB)\n",
        ")\n",
        "\n",
        "# **4. Adaptar el modelo AlexNet a CIFAR-10**\n",
        "# Crear un modelo secuencial personalizado que utilice las capas convolucionales preentrenadas\n",
        "model_tf = models.Sequential([\n",
        "    layers.Resizing(224, 224),  # Redimensionar imágenes de CIFAR-10 (32x32 -> 224x224)\n",
        "    alexnet_tf,                 # Modelo convolucional preentrenado VGG16\n",
        "    layers.Flatten(),           # Aplanar la salida de las convoluciones para conectarla a capas densas\n",
        "    layers.Dense(4096, activation='relu'),  # Primera capa densa con 4096 neuronas\n",
        "    layers.Dropout(0.5),        # Dropout para reducir el riesgo de sobreajuste\n",
        "    layers.Dense(4096, activation='relu'),  # Segunda capa densa con 4096 neuronas\n",
        "    layers.Dropout(0.5),        # Otro Dropout\n",
        "    layers.Dense(10, activation='softmax')  # Capa de salida para clasificar 10 clases de CIFAR-10\n",
        "])\n",
        "\n",
        "# **5. Congelar capas preentrenadas**\n",
        "# Las capas convolucionales de VGG16 se congelan (no se entrenan) para usar los pesos preentrenados\n",
        "for layer in alexnet_tf.layers:\n",
        "    layer.trainable = False  # Desactivar el entrenamiento de las capas preentrenadas\n",
        "\n",
        "# **6. Compilar el modelo**\n",
        "model_tf.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),    # Optimizador Adam con tasa de aprendizaje ajustada a 0.0005\n",
        "    loss=\"categorical_crossentropy\",        # Función de pérdida para clasificación multiclase\n",
        "    metrics=[\"accuracy\"]                    # Métrica de evaluación: precisión\n",
        ")\n",
        "\n",
        "# **7. Entrenar el modelo**\n",
        "history_tf = model_tf.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=64),  # Entrenamiento con datos aumentados (lotes de 64 imágenes)\n",
        "    validation_data=(X_test, y_test),              # Conjunto de datos de prueba para validación\n",
        "    epochs=10,                                     # Número de épocas: 10\n",
        "    verbose=2                                      # Mostrar salida detallada durante el entrenamiento\n",
        ")\n",
        "\n",
        "# **8. Evaluar el modelo en el conjunto de prueba**\n",
        "test_loss_tf, test_acc_tf = model_tf.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy AlexNet (TF Pretrained): {test_acc_tf}\")  # Imprime la precisión final\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "La2kmFGQQKTg",
        "g_YAJLC2QVFh"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
