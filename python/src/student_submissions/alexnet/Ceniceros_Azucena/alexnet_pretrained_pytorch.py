# -*- coding: utf-8 -*-
"""AlexNet_pretrained_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ianer2jpFkwhGyZWuSIHYuK6RN5OeZhy

# **AlexNet preentrenado en PyTorch**

Instalación de librerias/herramientas necesarias
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import os
import pickle
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""Cargar el archivo CIFAR-10 y devolver el diccionario de datos"""

def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

data_dir = '/content/drive/My Drive/cifar-10-batches-py'

"""Cargar los datos de CIFAR-10 y procesarlos"""

def load_cifar10_data(data_dir):
    train_data = []
    train_labels = []

    # Cargar los batches

    for i in range(1, 6):
        batch = unpickle(os.path.join(data_dir, f"data_batch_{i}"))
        train_data.append(batch[b'data'])
        train_labels += batch[b'labels']

   # Convertir los datos en un array y hacer reshape
    train_data = np.concatenate(train_data)
    train_data = train_data.reshape((train_data.shape[0], 3, 32, 32))

    return train_data, train_labels

train_data, train_labels = load_cifar10_data(data_dir)

    # Cargar datos de prueba y hacer reshape
test_batch = unpickle(os.path.join(data_dir, "test_batch"))
test_data = test_batch[b'data']
test_labels = test_batch[b'labels']
test_data = test_data.reshape((test_data.shape[0], 3, 32, 32))

# Redimensionar a 224x224

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Aplicar transformaciones a los datos de entrenamiento y prueba
train_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

"""Cargar modelo preentrenado"""

model = torchvision.models.alexnet(pretrained=True)

# Modificar la capa final para ajustarse a CIFAR
model.classifier[6] = nn.Linear(4096, 10)

# Definir la función de pérdida y el optimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Configurar el dispositivo
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""Entrenamiento del modelo"""

num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct/total:.2f}%")

"""Evaluación del modelo"""

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Test Accuracy: {100 * correct / total:.2f}%")