{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo en Pytroch\n",
    "En esta seccion importamos las funciones que se usaran en la creacion del modelo AlexNet desde scratch en Pytorch, asi como verificar si se puede usar la tarjeta grafica integrada de la PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion del modelo\n",
    "En esta parte ya creamos el modelo AlexNet con los requisitos mencionados en calse, 5 convoluciones, 3 maxpoolings y 3 redes densas con activciones ReLu y dos funciones dropout para evitar el overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(9216, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "        self.cn1 = nn.Conv2d(3, 64, 11, stride=4)\n",
    "        self.cn2 = nn.Conv2d(64, 192, 5, stride=1)\n",
    "        self.cn3 = nn.Conv2d(192, 384, 3, stride=1)\n",
    "        self.cn4 = nn.Conv2d(384, 256, 3, stride=1)\n",
    "        self.cn5 = nn.Conv2d(256, 256, 3, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cn1(x))\n",
    "        x = F.max_pool2d(x, (3, 3), stride = 2)\n",
    "        x = F.relu(self.cn2(x))\n",
    "        x = F.max_pool2d(x, (3, 3), stride = 2)\n",
    "        x = F.relu(self.cn3(x))\n",
    "        x = F.relu(self.cn4(x))\n",
    "        x = F.relu(self.cn5(x))\n",
    "        x = F.max_pool2d(x, (3, 3), stride = 2)\n",
    "        x = F.adaptive_avg_pool2d(x, (6, 6))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignamos el modelo a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "En esta seccion se usa el mismo codigo que se vio en clase para la carga de datos, pero con un batch size distinto, en este caso se uso 128 ya que asi lo permitio la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # AlexNet expects 224x224 images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se defininen el criterio de optimizacion y la funcion de optimizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamineto \n",
    "En esta celda se entrena por 20 epocas el modelo tardando de 15 a 20 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.445\n",
      "[2] loss: 0.375\n",
      "[3] loss: 0.311\n",
      "[4] loss: 0.259\n",
      "[5] loss: 0.225\n",
      "[6] loss: 0.195\n",
      "[7] loss: 0.172\n",
      "[8] loss: 0.152\n",
      "[9] loss: 0.133\n",
      "[10] loss: 0.117\n",
      "[11] loss: 0.102\n",
      "[12] loss: 0.086\n",
      "[13] loss: 0.072\n",
      "[14] loss: 0.062\n",
      "[15] loss: 0.052\n",
      "[16] loss: 0.043\n",
      "[17] loss: 0.038\n",
      "[18] loss: 0.032\n",
      "[19] loss: 0.029\n",
      "[20] loss: 0.025\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / 2000:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del modelo\n",
    "Se prueba el modelo con los datos de testing, y en general se obtinen una accuracy de 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 75.33 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'modelo_entrenado.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'modelo_completo.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalua el modelo por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 79.31 %\n",
      "Accuracy of car   : 78.57 %\n",
      "Accuracy of bird  : 72.73 %\n",
      "Accuracy of cat   : 52.94 %\n",
      "Accuracy of deer  : 70.37 %\n",
      "Accuracy of dog   : 72.73 %\n",
      "Accuracy of frog  : 80.56 %\n",
      "Accuracy of horse : 72.00 %\n",
      "Accuracy of ship  : 84.38 %\n",
      "Accuracy of truck : 79.49 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]:5s} : {100 * class_correct[i] / class_total[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo pre entrenado en Pytorch de AlexNet\n",
    "Cargamos el mdoelo preentrenado de AlexNet con solo 10 categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galo/Diplomado/python/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/galo/Diplomado/python/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelp = torchvision.models.alexnet(pretrained=True)\n",
    "modelp.eval()\n",
    "num_features = modelp.classifier[6].in_features\n",
    "modelp.classifier[6] = nn.Linear(num_features, 10) # 10 output classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(modelp.parameters(), lr=0.001, momentum=0.9)\n",
    "modelp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.127\n",
      "[2] loss: 0.075\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = modelp(inputs)\n",
    "        # Ensure labels are long type\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels) # Corrected order: outputs, labels\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / 2000:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del medoleo preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86.38 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = modelp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 82.76 %\n",
      "Accuracy of car   : 92.86 %\n",
      "Accuracy of bird  : 93.94 %\n",
      "Accuracy of cat   : 82.35 %\n",
      "Accuracy of deer  : 85.19 %\n",
      "Accuracy of dog   : 66.67 %\n",
      "Accuracy of frog  : 88.89 %\n",
      "Accuracy of horse : 92.00 %\n",
      "Accuracy of ship  : 93.75 %\n",
      "Accuracy of truck : 97.44 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = modelp(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]:5s} : {100 * class_correct[i] / class_total[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coomparacion de los modelos en Pytorch\n",
    "Es claro que el modelo preentrenado es  mmucho mas rapido y eficaz que el modleo que se creo desde cero, el modleo preentrenado sse tardo aproximadamente dos minutos y medio en completar tan solo dos epocas en cambio el nuevo se tardo veinte minutos para 20 epocas, en cuanto a epocas hablamso se tardan masomenos lo mismo. Un punto que creo   haber notaod es que en el nuevo modelo parece haber overfitting ya que la funcion de perdida disminuye muy rapido y ademas es incluso menor a la del modelo preentrenado, eso quiere decir que para los datos con los que se entrena parece funcionar demasiado bien pero al salir a conocer nuevos datos no resulta tan efectivo. Con metodos que traten de evitar el overfitting creo es posible mejorar aun mas el modelo.\n",
    "Otro punto que me parece interesante mencionar es que a ambos modelos les cuesta trabajo reconocer a los gatos y a los perros, y el modleo preentrenado parece tener mas variacion en la precision de las predicciones, en cambio el nuevo es peor pero mas constante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
