{"cells":[{"cell_type":"code","source":["!pip install rouge-score"],"metadata":{"id":"3yMmEjHfeScv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742504732151,"user_tz":360,"elapsed":2313,"user":{"displayName":"Enrique Gómez Cruz","userId":"15976468129285493895"}},"outputId":"9e1282bd-9b16-41f8-9d53-d3723687d1a7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":882,"status":"ok","timestamp":1742504733042,"user":{"displayName":"Enrique Gómez Cruz","userId":"15976468129285493895"},"user_tz":360},"id":"dxcOFuNOXHWQ","outputId":"9427f757-3c62-4abb-9b7d-5cd882059a1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","text_file = '/content/drive/MyDrive/Colab Notebooks/corpus/spa.txt'\n","glove_file = '/content/drive/MyDrive/Colab Notebooks/glove/glove.6B.100d.txt'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":38337,"status":"error","timestamp":1742504771378,"user":{"displayName":"Enrique Gómez Cruz","userId":"15976468129285493895"},"user_tz":360},"id":"bR-9Fa-TXZ-s","outputId":"9e4529bc-49f7-4189-c466-88d0a4b988ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["(\"That's the law.\", '[start] Esta es una ley. [end]')\n","('Japan depends on Arab countries for oil.', '[start] Japón depende de los países árabes para el petróleo. [end]')\n","(\"She's curious to find out who sent the flowers.\", '[start] Ella quiere saber quién le envió las flores. [end]')\n","('Is it a trap?', '[start] ¿Acaso es una trampa? [end]')\n","('Give me a little bit more.', '[start] Dadme un poco más. [end]')\n","141543 total pairs\n","99081 training pairs\n","21231 validation pairs\n","21231 test pairs\n","inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n","Found 400000 word vectors.\n","Converted 12516 words (331 misses)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m1,286,900\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m1,286,900\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │        \u001b[38;5;34m734,648\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │      \u001b[38;5;34m1,057,348\u001b[0m │ positional_embedding_… │\n","│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)      │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n","│                           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ transformer_decoder[\u001b[38;5;34m0\u001b[0m… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12849\u001b[0m)    │      \u001b[38;5;34m1,297,749\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,286,900</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,286,900</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">734,648</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_decoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,057,348</span> │ positional_embedding_… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)      │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│                           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12849</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,297,749</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,663,545\u001b[0m (21.60 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,663,545</span> (21.60 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,378,645\u001b[0m (16.70 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,378,645</span> (16.70 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,284,900\u001b[0m (4.90 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,900</span> (4.90 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"InternalError","evalue":"Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-3-ef3950d6fa4f>\", line 425, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nCustomCall failed: Buffers have different size at runtime\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_8963]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ef3950d6fa4f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m )\n\u001b[0;32m--> 425\u001b[0;31m transformer.fit(\n\u001b[0m\u001b[1;32m    426\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-3-ef3950d6fa4f>\", line 425, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nCustomCall failed: Buffers have different size at runtime\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_8963]"]}],"source":["import random\n","import string\n","import re\n","import numpy as np\n","\n","import tensorflow.data as tf_data\n","import tensorflow.strings as tf_strings\n","from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n","\n","import keras\n","import keras_hub\n","from keras import layers\n","from keras import ops\n","from keras.layers import TextVectorization\n","\n","\"\"\"\n","## Parameters\n","\"\"\"\n","# data constants\n","max_vocab_size = 15000\n","sequence_length = 20\n","batch_size = 64\n","\n","# model parameters\n","embed_dim = 100\n","latent_dim = 2048\n","num_heads = 8\n","epochs = 100  # This should be at least 30 for convergence\n","\n","\n","\"\"\"\n","## Parsing the data\n","\n","Each line contains a French sentence and its corresponding Spanish sentence.\n","The French sentence is the *source sequence* and Spanish one is the *target sequence*.\n","We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence.\n","\"\"\"\n","random.seed(10)\n","\n","with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","for line in lines:\n","    fre, spa = line.split(\"\\t\")\n","    spa = \"[start] \" + spa + \" [end]\"\n","    text_pairs.append((fre, spa))\n","\n","for _ in range(5):\n","    print(random.choice(text_pairs))\n","\n","\n","\"\"\"\n","Now, let's split the sentence pairs into a training set, a validation set,\n","and a test set.\n","\"\"\"\n","\n","random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_pairs)} total pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")\n","\n","\"\"\"\n","## Vectorizing the text data\n","\n","We'll use two instances of the `TextVectorization` layer to vectorize the text\n","data (one for French and one for Spanish),\n","that is to say, to turn the original strings into integer sequences\n","where each integer represents the index of a word in a vocabulary.\n","\n","The French layer will use the default string standardization (strip punctuation characters)\n","and splitting scheme (split on whitespace), while\n","the Spanish layer will use a custom standardization, where we add the character\n","`\"¿\"` to the set of punctuation characters to be stripped.\n","\"\"\"\n","\n","strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","def custom_standardization(input_string):\n","    lowercase = tf_strings.lower(input_string)\n","    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","\n","fre_vectorization = TextVectorization(\n","    max_tokens=max_vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","spa_vectorization = TextVectorization(\n","    max_tokens=max_vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_fre_texts = [pair[0] for pair in train_pairs]\n","train_spa_texts = [pair[1] for pair in train_pairs]\n","fre_vectorization.adapt(train_fre_texts)\n","spa_vectorization.adapt(train_spa_texts)\n","\n","\"\"\"\n","Next, we'll format our datasets.\n","\n","At each training step, the model will seek to predict target words N+1 (and beyond)\n","using the source sentence and the target words 0 to N.\n","\n","As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n","\n","- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n","`encoder_inputs` is the vectorized source sentence and `decoder_inputs` is the target sentence \"so far\",\n","that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n","- `target` is the target sentence offset by one step:\n","it provides the next words in the target sentence -- what the model will try to predict.\n","\"\"\"\n","\n","\n","def format_dataset(fre, spa):\n","    fre = fre_vectorization(fre)\n","    spa = spa_vectorization(spa)\n","    return (\n","        {\n","            \"encoder_inputs\": fre,\n","            \"decoder_inputs\": spa[:, :-1],\n","        },\n","        spa[:, 1:],\n","    )\n","\n","\n","def make_dataset(pairs):\n","    fre_texts, spa_texts = zip(*pairs)\n","    fre_texts = list(fre_texts)\n","    spa_texts = list(spa_texts)\n","    dataset = tf_data.Dataset.from_tensor_slices((fre_texts, spa_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.cache().shuffle(2048).prefetch(16)\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)\n","\n","\"\"\"\n","Let's take a quick look at the sequence shapes\n","(we have batches of 64 pairs, and all sequences are 20 steps long):\n","\"\"\"\n","\n","for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")\n","\n","\n","\"\"\"\n","# Pre-trained embeddings (GloVe model)\n","\"\"\"\n","embeddings_index = {}\n","with open(glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))\n","\n","# Prepare embedding matrix\n","voc = fre_vectorization.get_vocabulary()\n","vocab_size = len(voc) + 2\n","hits = 0\n","misses = 0\n","word_index = dict(zip(voc, range(len(voc))))\n","embedding_matrix = np.zeros((vocab_size, embed_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in embedding index will be all-zeros.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))\n","\n","\n","\"\"\"\n","## Building the model\n","\n","Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n","and a `TransformerDecoder` chained together. To make the model aware of word order,\n","we also use a `PositionalEmbedding` layer.\n","\n","The source sequence will be pass to the `TransformerEncoder`,\n","which will produce a new representation of it.\n","This new representation will then be passed\n","to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n","The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n","\n","A key detail that makes this possible is causal masking\n","(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n","The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n","sure that it only uses information from target tokens 0 to N when predicting token N+1\n","(otherwise, it could use information from the future, which would\n","result in a model that cannot be used at inference time).\n","\"\"\"\n","\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(dense_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n","        else:\n","            padding_mask = None\n","\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"dense_dim\": self.dense_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n","\n","\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","        if (not self.trainable):\n","          self.token_embeddings.trainable = False\n","          self.token_embeddings.build((1,))\n","          self.token_embeddings.set_weights([embedding_matrix])\n","\n","\n","    def call(self, inputs):\n","        length = ops.shape(inputs)[-1]\n","        positions = ops.arange(0, length, 1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return ops.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"sequence_length\": self.sequence_length,\n","                \"vocab_size\": self.vocab_size,\n","                \"embed_dim\": self.embed_dim,\n","            }\n","        )\n","        return config\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(latent_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        inputs, encoder_outputs = inputs\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","\n","        if mask is None:\n","            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n","        else:\n","            inputs_padding_mask, encoder_outputs_padding_mask = mask\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs,\n","            value=inputs,\n","            key=inputs,\n","            attention_mask=causal_mask,\n","            query_mask=inputs_padding_mask,\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            query_mask=inputs_padding_mask,\n","            key_mask=encoder_outputs_padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = ops.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = ops.arange(sequence_length)[:, None]\n","        j = ops.arange(sequence_length)\n","        mask = ops.cast(i >= j, dtype=\"int32\")\n","        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = ops.concatenate(\n","            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n","            axis=0,\n","        )\n","        return ops.tile(mask, mult)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"latent_dim\": self.latent_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n","\n","\n","\"\"\"\n","Next, we assemble the end-to-end model.\n","\"\"\"\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim, trainable=False)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","transformer = keras.Model(\n","   {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n","   decoder_outputs,\n","   name=\"transformer\",\n",")\n","\n","\"\"\"\n","## Training our model\n","\n","We'll use accuracy as a quick way to monitor training progress on the validation data.\n","Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n","\n","Here we only train for 1 epoch, but to get the model to actually converge\n","you should train for at least 30 epochs.\n","\"\"\"\n","\n","transformer.summary()\n","transformer.compile(\n","   \"rmsprop\",\n","   loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n","   metrics=[\"accuracy\"],\n",")\n","\n","# csv logger callback\n","csv_logger = CSVLogger(\"/content/drive/MyDrive/Colab Notebooks/transformer.training.log\")\n","\n","# model checkpoint callback\n","model_checkpoint = ModelCheckpoint(\n","    filepath=\"/content/drive/MyDrive/Colab Notebooks/transformer.checkpoint.keras\",\n","    monitor=\"val_accuracy\",\n","    mode=\"max\",\n","    save_best_only=True,\n",")\n","transformer.fit(\n","    train_ds,\n","    epochs=epochs,\n","    validation_data=val_ds,\n","    verbose=2,\n","    callbacks=[csv_logger, model_checkpoint],\n",")\n","\n","\"\"\"\n","## Decoding test sentences\n","\n","Finally, let's demonstrate how to translate brand new French sentences.\n","We simply feed into the model the vectorized French sentence\n","as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n","we hit the token `\"[end]\"`.\n","\"\"\"\n","\n","spa_vocab = spa_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = fre_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer(\n","            {\n","                \"encoder_inputs\": tokenized_input_sentence,\n","                \"decoder_inputs\": tokenized_target_sentence,\n","            }\n","        )\n","\n","        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n","        sampled_token_index = ops.convert_to_numpy(\n","            ops.argmax(predictions[0, i, :])\n","        ).item(0)\n","        sampled_token = spa_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","\n","test_fre_texts = [pair[0] for pair in test_pairs]\n","for _ in range(10):\n","    input_sentence = random.choice(test_fre_texts)\n","    translated = decode_sequence(input_sentence)\n","    print(input_sentence)\n","    print(translated)\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrM2WzOKs2L-","executionInfo":{"status":"aborted","timestamp":1742504771381,"user_tz":360,"elapsed":15,"user":{"displayName":"Enrique Gómez Cruz","userId":"15976468129285493895"}}},"outputs":[],"source":["\"\"\"\n","## Quantitative evaluation (Rouge metrics)\n","\"\"\"\n","rouge_1 = keras_hub.metrics.RougeN(order=1)\n","rouge_2 = keras_hub.metrics.RougeN(order=2)\n","\n","for test_pair in test_pairs[:30]:\n","    input_sentence = test_pair[0]\n","    reference_sentence = test_pair[1]\n","\n","    translated_sentence = decode_sequence(input_sentence)\n","    translated_sentence = (\n","        translated_sentence.replace(\"[PAD]\", \"\")\n","        .replace(\"[START]\", \"\")\n","        .replace(\"[END]\", \"\")\n","        .strip()\n","    )\n","\n","    rouge_1(reference_sentence, translated_sentence)\n","    rouge_2(reference_sentence, translated_sentence)\n","\n","print(\"ROUGE-1 Score: \", rouge_1.result())\n","print(\"ROUGE-2 Score: \", rouge_2.result())"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyM8qCcKXHACM08Uw/K7LQyy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}