{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqa4faYNSMVD"
      },
      "source": [
        " # Adaptación de *English-to-Spanish NMT by fchollet*\n",
        " El siguiente modelo se entreno desde cero. Posteriormente se hará el tratamiento con los embeddings' de GloVe.\n",
        "\n",
        " * Se implementa el modelo transformador de secuencia a secuencia\n",
        " * Entrenamiento para realizar traducciones.\n",
        " * Se almacena el modelo preentrenado para el uso futuro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y2MrRGBlSGt6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 09:12:08.700515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742656328.892058    6337 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742656328.946612    6337 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-22 09:12:09.358973: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0UjzTJdSZX6"
      },
      "source": [
        "Descargar el conjunto de datos de Anki *English-to-Spanish*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5QHOESsVSTE3"
      },
      "outputs": [],
      "source": [
        "#=text_file = keras.utils.get_file(\n",
        "    # fname=\"spa-eng.zip\",\n",
        "    # origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    # extract=True,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hX1lAcq6TfcZ"
      },
      "outputs": [],
      "source": [
        "#text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
        "#text_file = \"/content/drive/MyDrive/spa.txt\"\n",
        "text_file = \"spa-eng/spa.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4J9WLk6Se7o"
      },
      "source": [
        "Analisis de los datos.\n",
        "\n",
        "Cada línea del conjunto de datos contiene una oración en ingles y su correspondiente oración en español. La oración en inglés es la *source sequence*(oración fuente) y la oración en español es la *target sequence* (oración destino). Para cada token se antepone \"[start]\" al inicio y se agrega \"[end]\" al final de la oración en español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EX0f3tj6ShvU"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsVDpiz8SqBx"
      },
      "source": [
        "Vistazo a los pares de oraciones inglés-español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDHG2tmKSpe3",
        "outputId": "520c9219-c2c7-49ff-e405-176ef0def3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\"Don't do anything like that again.\", '[start] No vuelvas a hacer nada así. [end]')\n",
            "('Tom leaned forward and tapped the cab driver on the shoulder.', '[start] Tom se inclinó hacia delante y golpeó suavemente en el hombro al conductor del taxi. [end]')\n",
            "('Who do you want to speak to?', '[start] ¿Con quién quieres hablar? [end]')\n",
            "('Our ancestors arrived in this country 150 years ago.', '[start] Nuestros ancestros llegaron a este país hace 150 años. [end]')\n",
            "('Jonas Salk developed the polio vaccine in 1952.', '[start] Jonas Salk desarrolló la vacuna contra la polio en 1952. [end]')\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH1SVPQXdlHR"
      },
      "source": [
        "A continuación se dividen los pares de oraciones en datos de prueba y de entrenamiento de forma aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3IKCyJQSsju",
        "outputId": "eeafda89-dc03-4231-ef3e-6359e0514d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_8D7_DzdqYV"
      },
      "source": [
        "# Vectorización\n",
        "\n",
        "Se utilizaron dos instancias de la capa *TextVectorization* para vectorizar los datos de texto una para inglés y otra para español, para convertir las cadenas originales en secuencias de números enteros donde cada entero representa el índice de una palabra en un vocabulario.\n",
        "\n",
        "La capa de inglés utilizará la estandarización de cadenas predeterminada (eliminando los caracteres de puntuación) y el esquema de división (dividir por espacios), mientras que la capa de español utilizará una estandarización personalizada para remover carácteres de puntuación propios del lenguaje español.\n",
        "\n",
        "Nota: En un modelo de traducción automática de producción, no recomendaría eliminar los caracteres de puntuación en ninguno de los dos idiomas. En su lugar, recomendaría convertir cada carácter de puntuación en su propio token, lo cual se podría lograr proporcionando una función de división personalizada a la capa TextVectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N-ngKBaOS3sR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742656334.233108    6337 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3108 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
          ]
        }
      ],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "# 6.b\n",
        "ngrams = 3\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf_strings.lower(input_string)\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        "    ngrams=ngrams\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        "    ngrams=ngrams\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tx4MqyYeHGB"
      },
      "source": [
        "A continuación, se da formato a los conjuntos de datos.\n",
        "\n",
        "En cada paso de entrenamiento, el modelo intentará predecir las palabras objetivo N+1 (y posteriores) utilizando la oración fuente y las palabras objetivo de 0 a N.\n",
        "\n",
        "Para ello, el conjunto de datos de entrenamiento generará una tupla (entradas, objetivos), donde:\n",
        "\n",
        "* Entradas es un diccionario con las claves encoder_inputs y decoder_inputs. \n",
        "* encoder_inputs es la oración fuente vectorizada.\n",
        "* decoder_inputs es la oración objetivo con las palabras de 0 a N utilizadas para predecir la palabra N+1 (y posteriores) en la oración objetivo.\n",
        "* Objetivo es la oración objetivo desplazada por un paso: proporciona las siguientes palabras en la oración objetivo, lo que el modelo intentará predecir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l1aB6QuQS6cQ"
      },
      "outputs": [],
      "source": [
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Wc2ebReo4K"
      },
      "source": [
        "Formas de la secuencia: Se tienen lotes de 64 pares y todas las secuencias tienen una longitud de 20 pasos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwDWnbH_S8JF",
        "outputId": "efbbf479-9e10-43dc-816d-3dcb6abfc90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 09:12:18.561589: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khTsXH2KS_44"
      },
      "source": [
        "# Construcción del modelo\n",
        "\n",
        "Este modelo Transformer secuencia a secuencia consta de un *TransformerEncoder* y un *TransformerDecoder* encadenados. \n",
        "Para que el modelo reconozca el orden de las palabras, se utiliza una capa de *PositionalEmbedding*.\n",
        "\n",
        "La secuencia fuente envía al TransformerEncoder el cual genera una nueva representación de la misma. Esta nueva representación pasa al TransformerDecoder, junto con la secuencia objetivo hasta el momento (palabras objetivo de 0 a N). El TransformerDecoder intenta predecir las siguientes palabras en la secuencia objetivo (N+1 y posteriores).\n",
        "\n",
        "Un detalle clave que lo hace posible es el enmascaramiento causal (véase el método get_causal_attention_mask() en el TransformerDecoder). El TransformerDecoder ve todas las secuencias a la vez, por lo que debemos asegurarnos de que solo utilice la información de los tokens objetivo de 0 a N al predecir el token N+1 (de lo contrario, podría utilizar información del futuro, lo que daría como resultado un modelo que no se pueda utilizar en el momento de hacer la inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JXldm-YJS-NO"
      },
      "outputs": [],
      "source": [
        "import keras.ops as ops\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        inputs, encoder_outputs = inputs\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        if mask is None:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
        "        else:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            query_mask=inputs_padding_mask,\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            query_mask=inputs_padding_mask,\n",
        "            key_mask=encoder_outputs_padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9__hvxBfKkJ"
      },
      "source": [
        "A continuación se ensambla el modelo de extremo a extremo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "# Entrada y salida del encoder y decoder\n",
        "encoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = layers.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "# Modelo Transformer final\n",
        "transformer = keras.Model(\n",
        "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")\n",
        "\n",
        "# Resumen del modelo\n",
        "#transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "\n",
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfAAocOGTGV7"
      },
      "source": [
        "# Entrenando el modelo\n",
        "\n",
        "Se utiliza la precisión como una forma rápida de monitorear el progreso del entrenamiento con los datos de validación. \n",
        "También para la traducción automática suelen utilizar otras métricas como *BLEU*, *ROUGE*.\n",
        "\n",
        "Para que el modelo converja realmente se debe entrenar durante al menos 30 épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "XOm6L5OdTG8c",
        "outputId": "f290e3fe-031e-4660-f3ec-b42db7503731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1742657035.421724    6399 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
            "2025-03-22 09:23:59.835259: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'copy_fusion_1', 464 bytes spill stores, 484 bytes spill loads\n",
            "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
            "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_3', 104 bytes spill stores, 104 bytes spill loads\n",
            "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_1', 104 bytes spill stores, 104 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 946/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 173ms/step - Accuracy: 0.5059 - loss: 2.8773"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1742657203.690929    6398 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 947/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 178ms/step - Accuracy: 0.5059 - loss: 2.8772"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 09:26:48.738803: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'copy_fusion_1', 464 bytes spill stores, 484 bytes spill loads\n",
            "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - Accuracy: 0.5093 - loss: 2.8423"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1742657271.641143    6398 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
            "W0000 00:00:1742657279.134741    6398 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 186ms/step - Accuracy: 0.5094 - loss: 2.8422 - val_Accuracy: 0.5561 - val_loss: 2.2841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:209: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
            "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 260.13 seconds\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'val_accuracy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Mostrar métricas finales\u001b[39;00m\n\u001b[32m     59\u001b[39m final_acc = history.history[\u001b[33m\"\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m final_val_acc = \u001b[43mhistory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval_accuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[-\u001b[32m1\u001b[39m]\n\u001b[32m     61\u001b[39m final_loss = history.history[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     62\u001b[39m final_val_loss = history.history[\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n",
            "\u001b[31mKeyError\u001b[39m: 'val_accuracy'"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Iniciar el tiempo\n",
        "start_time = time.time()\n",
        "\n",
        "# Callbacks para guardar logs, mejores modelos y evitar sobreentrenamiento\n",
        "csv_logger = CSVLogger(\"training_logs.csv\", append=True)  # Guarda logs en CSV\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"transformer_best.keras\",  # Guarda el mejor modelo\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",  # Detiene si la pérdida no mejora\n",
        "    patience=5,  # Número de épocas sin mejora antes de detener\n",
        "    restore_best_weights=True  # Restaura los mejores pesos encontrados\n",
        ")\n",
        "\n",
        "# 6.a Usar más de 30 épocas\n",
        "new_epochs = 1\n",
        "\n",
        "# 6.c Cambiar la tasa de aprendizaje\n",
        "lr = 1e-4  # Prueba con 1e-3, 5e-4, 1e-5, etc.\n",
        "# 6.d Cambiar el optimizador\n",
        "optimizer = Adam(learning_rate=lr) # probar otros\n",
        "# optimizer = RMSprop(learning_rate=1e-4)\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
        "    metrics=[\"Accuracy\"])\n",
        "\n",
        "\n",
        "# Entrenamiento\n",
        "history = transformer.fit(\n",
        "    train_ds,\n",
        "    epochs=new_epochs,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[csv_logger, checkpoint_callback, early_stopping]\n",
        ")\n",
        "\n",
        "# Guardar modelo completo\n",
        "transformer.save(\"transformer_updated.keras\")\n",
        "\n",
        "# Guardar solo los pesos\n",
        "#transformer.save_weights(\"transformer_weights.h5\")\n",
        "\n",
        "# Medir el tiempo total\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Training completed in {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5220\n",
            "Final Validation Accuracy: 0.5561\n",
            "Final Training Loss: 2.7112\n",
            "Final Validation Loss: 2.2841\n"
          ]
        }
      ],
      "source": [
        "# Mostrar métricas finales\n",
        "# print(history.history.keys())\n",
        "final_acc = history.history[\"Accuracy\"][-1]\n",
        "final_val_acc = history.history[\"val_Accuracy\"][-1]\n",
        "final_loss = history.history[\"loss\"][-1]\n",
        "final_val_loss = history.history[\"val_loss\"][-1]\n",
        "\n",
        "print(f\"Final Training Accuracy: {final_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"Final Training Loss: {final_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL4UEjKKTLRJ"
      },
      "source": [
        "# Decodificación de oraciones de prueba\n",
        "A continuación se demostrará cómo traducir oraciones nuevas en inglés. Simplemente introducimos en el modelo la oración vectorizada en inglés y el token de destino \"[start]\". Luego, generamos repetidamente el siguiente token hasta llegar al token \"[end]\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-VEoOZnTL0G",
        "outputId": "3a901653-7279-40ab-edd4-c9eeba33138a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "She has seven sons. [start] ella tiene las personas [end]\n",
            "Don't expect others to help you. [start] no te [UNK] a los ayuda [end]\n",
            "He gave me not just advice, but money as well. [start] Él me dio no le dio dinero pero dinero pero a la dinero [end]\n",
            "There must've been a tacit understanding between them. [start] tiene que haber [UNK] un [UNK] entre ellos [end]\n",
            "This data is for my thesis. [start] este [UNK] es por mi [UNK] [end]\n",
            "How was your summer? [start] cómo fue tu verano [end]\n",
            "I didn't know that. [start] no sabía eso [end]\n",
            "He rolled over in his sleep. [start] Él se [UNK] en su trabajo [end]\n",
            "We hit a deer. [start] [UNK] a un [UNK] [end]\n",
            "You can start right now. [start] puedes [UNK] ahora [end]\n"
          ]
        }
      ],
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            {\n",
        "                \"encoder_inputs\": tokenized_input_sentence,\n",
        "                \"decoder_inputs\": tokenized_target_sentence,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(10):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence, translated)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* 6.e Cambiar las métricas. \n",
        "* 6.f Se BLEU.\n",
        "* 6.g Se utiliza Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79yLRIpnXE3D",
        "outputId": "84b0b56f-2a5d-44ab-f57a-37342e2007c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from rouge-score) (2.1.0)\n",
            "Requirement already satisfied: nltk in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Tom raises Arabian horses.\n",
            "Reference: [start] Tom cría caballos árabes. [end]\n",
            "Translated: [start] tom [UNK] los [UNK] los estudiantes [end]\n",
            "ROUGE-1 Precision: 0.3750, Recall: 0.4286, F1-score: 0.4000\n",
            "ROUGE-2 Precision: 0.1429, Recall: 0.1667, F1-score: 0.1538\n",
            "--------------------------------------------------\n",
            "Input: It's easy for monkeys to climb trees.\n",
            "Reference: [start] Para los monos es sencillo trepar árboles. [end]\n",
            "Translated: [start] es fácil para [UNK] para [UNK] [end]\n",
            "ROUGE-1 Precision: 0.4444, Recall: 0.4444, F1-score: 0.4444\n",
            "ROUGE-2 Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "--------------------------------------------------\n",
            "Input: After the accident, the police told the crowd to keep back.\n",
            "Reference: [start] Tras el accidente, la policía le dijo a la multitud que se alejaran. [end]\n",
            "Translated: [start] después de el accidente de la policía se le dijo a la policía [end]\n",
            "ROUGE-1 Precision: 0.6667, Recall: 0.7500, F1-score: 0.7059\n",
            "ROUGE-2 Precision: 0.3529, Recall: 0.4000, F1-score: 0.3750\n",
            "--------------------------------------------------\n",
            "Input: There are still a lot of things I don't know about Tom.\n",
            "Reference: [start] Aun hay un montón de cosas que desconozco sobre Tom. [end]\n",
            "Translated: [start] todavía hay mucho de cosas que no sé de tom [end]\n",
            "ROUGE-1 Precision: 0.5385, Recall: 0.5385, F1-score: 0.5385\n",
            "ROUGE-2 Precision: 0.2500, Recall: 0.2500, F1-score: 0.2500\n",
            "--------------------------------------------------\n",
            "Input: How could I forget?\n",
            "Reference: [start] ¿Cómo podría olvidarlo? [end]\n",
            "Translated: [start] cómo podría [UNK] [end]\n",
            "ROUGE-1 Precision: 0.8571, Recall: 0.8571, F1-score: 0.8571\n",
            "ROUGE-2 Precision: 0.6667, Recall: 0.6667, F1-score: 0.6667\n",
            "--------------------------------------------------\n",
            "Input: How high can you jump?\n",
            "Reference: [start] ¿Qué tan alto puedes brincar? [end]\n",
            "Translated: [start] cómo se puede [UNK] [end]\n",
            "ROUGE-1 Precision: 0.4286, Recall: 0.4286, F1-score: 0.4286\n",
            "ROUGE-2 Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n",
            "--------------------------------------------------\n",
            "Input: That surprised Tom.\n",
            "Reference: [start] Eso sorprendió a Tom. [end]\n",
            "Translated: [start] eso se [UNK] a tom [end]\n",
            "ROUGE-1 Precision: 0.7143, Recall: 0.8333, F1-score: 0.7692\n",
            "ROUGE-2 Precision: 0.5000, Recall: 0.6000, F1-score: 0.5455\n",
            "--------------------------------------------------\n",
            "Input: I feel sad when I think about all the people who die in wars.\n",
            "Reference: [start] Me siento muy triste cuando pienso en toda la gente que muere en las guerras. [end]\n",
            "Translated: [start] me siento el abogado cuando creo que la gente en la gente [end]\n",
            "ROUGE-1 Precision: 0.6429, Recall: 0.5294, F1-score: 0.5806\n",
            "ROUGE-2 Precision: 0.2308, Recall: 0.1875, F1-score: 0.2069\n",
            "--------------------------------------------------\n",
            "Input: He complains all the time.\n",
            "Reference: [start] Él se queja todo el tiempo. [end]\n",
            "Translated: [start] Él [UNK] todo el tiempo [end]\n",
            "ROUGE-1 Precision: 0.8571, Recall: 0.7500, F1-score: 0.8000\n",
            "ROUGE-2 Precision: 0.6667, Recall: 0.5714, F1-score: 0.6154\n",
            "--------------------------------------------------\n",
            "Input: She has gone to Italy.\n",
            "Reference: [start] Ella fue a Italia. [end]\n",
            "Translated: [start] ella se ha ido a las mujeres [end]\n",
            "ROUGE-1 Precision: 0.4444, Recall: 0.6667, F1-score: 0.5333\n",
            "ROUGE-2 Precision: 0.1250, Recall: 0.2000, F1-score: 0.1538\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
        "\n",
        "for test_pair in test_pairs[:10]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "    translated_sentence = decode_sequence(input_sentence)\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    scores = rouge_scorer.score(reference_sentence, translated_sentence)\n",
        "    print(f\"Input: {input_sentence}\")\n",
        "    print(f\"Reference: {reference_sentence}\")\n",
        "    print(f\"Translated: {translated_sentence}\")\n",
        "    print(f\"ROUGE-1 Precision: {scores['rouge1'].precision:.4f}, Recall: {scores['rouge1'].recall:.4f}, F1-score: {scores['rouge1'].fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-2 Precision: {scores['rouge2'].precision:.4f}, Recall: {scores['rouge2'].recall:.4f}, F1-score: {scores['rouge2'].fmeasure:.4f}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-P7G0zRvfla",
        "outputId": "3df615d6-829b-4db4-e675-d2fad0fc9445"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'scores' is a list of dictionaries, each containing the ROUGE scores for a test pair.\n",
        "# If not, adjust accordingly based on your actual data structure.\n",
        "\n",
        "# Crear una lista de diccionarios para almacenar los resultados\n",
        "rows = []\n",
        "for test_pair in test_pairs[:10]:\n",
        "  input_sentence = test_pair[0]\n",
        "  reference_sentence = test_pair[1]\n",
        "  translated_sentence = decode_sequence(input_sentence)\n",
        "  translated_sentence = (\n",
        "      translated_sentence.replace(\"[PAD]\", \"\")\n",
        "      .replace(\"[START]\", \"\")\n",
        "      .replace(\"[END]\", \"\")\n",
        "      .strip()\n",
        "  )\n",
        "  scores = rouge_scorer.score(reference_sentence, translated_sentence)\n",
        "\n",
        "  row = {\n",
        "      \"Input\": input_sentence,\n",
        "      \"Reference\": reference_sentence,\n",
        "      \"Translated\": translated_sentence,\n",
        "      \"ROUGE-1 Precision\": scores['rouge1'].precision,\n",
        "      \"ROUGE-1 Recall\": scores['rouge1'].recall,\n",
        "      \"ROUGE-1 F1-score\": scores['rouge1'].fmeasure,\n",
        "      \"ROUGE-2 Precision\": scores['rouge2'].precision,\n",
        "      \"ROUGE-2 Recall\": scores['rouge2'].recall,\n",
        "      \"ROUGE-2 F1-score\": scores['rouge2'].fmeasure,\n",
        "  }\n",
        "  rows.append(row)\n",
        "\n",
        "# Create a Pandas DataFrame from the list of dictionaries\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "df.to_csv(\"rouge_scores_II.csv\", index=False)\n",
        "# df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/rouge_scores.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN198vCLwIS6"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Crear una lista de diccionarios para almacenar los resultados\n",
        "rows = []\n",
        "smoother = SmoothingFunction().method1  # Suavizado para evitar BLEU=0 en frases cortas\n",
        "\n",
        "for test_pair in test_pairs[:10]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "    translated_sentence = decode_sequence(input_sentence)\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    # Tokenizar las oraciones\n",
        "    reference_tokens = [reference_sentence.split()]\n",
        "    translated_tokens = translated_sentence.split()\n",
        "\n",
        "    # Calcular BLEU con 1-gram, 2-gram, 3-gram y 4-gram\n",
        "    bleu1 = sentence_bleu(reference_tokens, translated_tokens, weights=(1, 0, 0, 0), smoothing_function=smoother)\n",
        "    bleu2 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoother)\n",
        "    bleu3 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoother)\n",
        "    bleu4 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoother)\n",
        "\n",
        "    row = {\n",
        "        \"Input\": input_sentence,\n",
        "        \"Reference\": reference_sentence,\n",
        "        \"Translated\": translated_sentence,\n",
        "        \"BLEU-1\": bleu1,\n",
        "        \"BLEU-2\": bleu2,\n",
        "        \"BLEU-3\": bleu3,\n",
        "        \"BLEU-4\": bleu4,\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# Crear DataFrame y exportar a CSV\n",
        "df = pd.DataFrame(rows)\n",
        "# df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/bleu_scores.csv\", index=False)\n",
        "df.to_csv(\"bleu_scores.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Martinez_Selene-BhocuyRJ",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
