{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 09:44:54.372300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742658294.392988    9335 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742658294.399177    9335 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 09:44:54.419240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib, random, string, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data # type: ignore\n",
    "import tensorflow.strings as tf_strings # type: ignore\n",
    "import keras.ops as ops # type: ignore\n",
    "from tensorflow import keras  \n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization # type: ignore\n",
    "from tensorflow.keras.callbacks import CSVLogger # type: ignore\n",
    "from tensorflow.keras.layers import TextVectorization # type: ignore\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained word embeddings\n",
    "Se descargaron los 'embeddings' de GloVe (822M zip file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargar los embeddings de GloVe\n",
    "\n",
    "The archive contains text-encoded vectors of various sizes: 50-dimensional, 100-dimensional, 200-dimensional, 300-dimensional. We'll use the 100D ones.\n",
    "\n",
    "Let's make a dict mapping words (strings) to their NumPy vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 400001 palabras de GloVe.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "def load_glove_embeddings(path_glove, embedding_dim=embedding_dim):\n",
    "    \"Carga los embeddings de GloVe desde un archivo y los convierte en un diccionario de palabras a vectores\"\n",
    "    embeddings_index = {}\n",
    "    with open(path_glove, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Se cargaron {len(embeddings_index)} palabras de GloVe.\")\n",
    "    return embeddings_index\n",
    "\n",
    "# Cargar los embeddings GloVe de 50 dimensiones\n",
    "path_glove = \"glove.6B/glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove_embeddings(path_glove, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crear una matriz de embeddings para el vocabulario\n",
    "\n",
    "Se requiere una matriz de embeddings que coincida con las palabras en el vocabulario, ya que solo las palabras que están en el vocabulario del modelo transformer deben tener un embedding correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardaron los datos de spa.txt en dataset.parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_file = \"/content/drive/MyDrive/spa.txt\" \n",
    "text_file = \"spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))\n",
    "\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 83276, Val: 17844, Test: 17844\n"
     ]
    }
   ],
   "source": [
    "# Verificar tamaños\n",
    "print(f\"Train: {len(train_pairs)}, Val: {len(val_pairs)}, Test: {len(test_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742658303.305962    9335 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 221 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "# 6.b\n",
    "ngrams = 3\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    ngrams=ngrams\n",
    ")\n",
    "spa_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    "    ngrams=ngrams\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Obtener el vocabulario y crear el índice de palabras:\n",
    "\n",
    "Se tiene el vocabulario de español en *spa_vectorization*, el cual esta adaptado a partir del conjunto de datos de entrenamiento. Este se usara para crear la matriz de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el vocabulario de las palabras en español\n",
    "spa_vocab = spa_vectorization.get_vocabulary()\n",
    "# Crear un diccionario de índice de palabras (índice -> palabra)\n",
    "spa_index_lookup = dict(zip(spa_vocab, range(len(spa_vocab))))\n",
    "\n",
    "eng_vocab = eng_vectorization.get_vocabulary()\n",
    "# Crear un diccionario de índice de palabras (índice -> palabra)\n",
    "eng_index_lookup = dict(zip(eng_vocab, range(len(eng_vocab))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí spa_vocab es la lista de todas las palabras que spa_vectorization aprendió durante el adapt() del conjunto de datos en español. En el caso de traducción, usualmente se asigna un embedding a la secuencia de destino.\n",
    "\n",
    "2. Crear la matriz de embeddings usando GloVe:\n",
    "\n",
    "Se utilizará el diccionario de embeddings de GloVe cargado anteriormente y asignaremos sus vectores a las palabras de nuestro vocabulario de español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseas usar embeddings preentrenados de GloVe para ambas lenguas, deberías hacerlo tanto para el inglés como para el español, creando matrices de embeddings para ambos idiomas y luego usarlas en sus respectivas capas de embedding del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función create_embedding_matrix crea una matriz de embeddings para las palabras en el vocabulario utilizando el diccionario de embeddings de GloVe cargado anteriormente. Para cada palabra en el vocabulario, la función intenta encontrar su vector correspondiente en el diccionario de embeddings de GloVe. Si la palabra se encuentra, su vector se asigna a la matriz de embeddings. Si no se encuentra la palabra, su vector se asigna a cero o al vector [UNK] para indicar que la palabra no está en el diccionario. Esta matriz se utilizará posteriormente en una capa de embeddings del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 3139 words (11860 misses)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embedding matrix\n",
    "#embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "def create_embedding_matrix(vocab, embeddings_index, embedding_dim=100,  oov_token=\"[UNK]\", pad_token=\"[PAD]\"):\n",
    "    \"\"\"Crea una matriz de embeddings para las palabras en el vocabulario\"\"\"\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(vocab), embedding_dim))  # +1 para el token 0\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    # Obtener el índice para [UNK] y [PAD]\n",
    "    oov_token_idx = vocab.get(oov_token, None)\n",
    "    pad_token_idx = vocab.get(pad_token, None)\n",
    "\n",
    "    for word, i in vocab.items():\n",
    "        if word == oov_token or word == pad_token:  # Si es el token [UNK] o [PAD], lo dejamos en ceros\n",
    "            continue  # No asignamos vectores a [UNK] y [PAD]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "            # Si no se encuentra la palabra en GloVe, asigna el vector [UNK] o lo deja en ceros\n",
    "            if oov_token_idx is not None:\n",
    "                embedding_matrix[oov_token_idx] = np.zeros(embedding_dim)  # Aquí asignamos un vector de ceros para [UNK]\n",
    "\n",
    "    print(f\"Converted {hits} words ({misses} misses)\")\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix_eng = create_embedding_matrix(eng_index_lookup, embeddings_index, embedding_dim=100)\n",
    "#embedding_matrix_spa = create_embedding_matrix(spa_index_lookup, embeddings_index, embedding_dim=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "num_tokens = len(eng_index_lookup)\n",
    "embedding_dim = 100\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((1,))\n",
    "embedding_layer.set_weights([embedding_matrix_eng])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.ops as ops\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"dense_dim\": self.dense_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        positions = ops.arange(0, length, 1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        inputs, encoder_outputs = inputs\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        if mask is None:\n",
    "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
    "        else:\n",
    "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask,\n",
    "            query_mask=inputs_padding_mask,\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            query_mask=inputs_padding_mask,\n",
    "            key_mask=encoder_outputs_padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = ops.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = ops.arange(sequence_length)[:, None]\n",
    "        j = ops.arange(sequence_length)\n",
    "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
    "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = ops.concatenate(\n",
    "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
    "            axis=0,\n",
    "        )\n",
    "        return ops.tile(mask, mult)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages/keras/src/layers/layer.py:395: UserWarning: `build()` was called on layer 'positional_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages/keras/src/layers/layer.py:395: UserWarning: `build()` was called on layer 'positional_embedding_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages/keras/src/layers/layer.py:395: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/luna/.local/share/virtualenvs/Martinez_Selene-BhocuyRJ/lib/python3.12/site-packages/keras/src/layers/layer.py:395: UserWarning: `build()` was called on layer 'transformer_decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reconstruir el modelo\n",
    "# Importa las clases personalizadas\n",
    "path_to_model = \"English_to_Spanish_II.keras\"\n",
    "transformer = keras.models.load_model(path_to_model,\n",
    "    custom_objects={\n",
    "        \"TransformerEncoder\": TransformerEncoder,\n",
    "        \"PositionalEmbedding\": PositionalEmbedding,\n",
    "        \"TransformerDecoder\": TransformerDecoder,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso 0: Forma (15000, 256)\n",
      "Peso 1: Forma (20, 256)\n",
      "Peso 2: Forma (15000, 256)\n",
      "Peso 3: Forma (20, 256)\n",
      "Peso 4: Forma (256, 8, 256)\n",
      "Peso 5: Forma (8, 256)\n",
      "Peso 6: Forma (256, 8, 256)\n",
      "Peso 7: Forma (8, 256)\n",
      "Peso 8: Forma (256, 8, 256)\n",
      "Peso 9: Forma (8, 256)\n",
      "Peso 10: Forma (8, 256, 256)\n",
      "Peso 11: Forma (256,)\n",
      "Peso 12: Forma (256, 2048)\n",
      "Peso 13: Forma (2048,)\n",
      "Peso 14: Forma (2048, 256)\n",
      "Peso 15: Forma (256,)\n",
      "Peso 16: Forma (256,)\n",
      "Peso 17: Forma (256,)\n",
      "Peso 18: Forma (256,)\n",
      "Peso 19: Forma (256,)\n",
      "Peso 20: Forma (256, 8, 256)\n",
      "Peso 21: Forma (8, 256)\n",
      "Peso 22: Forma (256, 8, 256)\n",
      "Peso 23: Forma (8, 256)\n",
      "Peso 24: Forma (256, 8, 256)\n",
      "Peso 25: Forma (8, 256)\n",
      "Peso 26: Forma (8, 256, 256)\n",
      "Peso 27: Forma (256,)\n",
      "Peso 28: Forma (256, 8, 256)\n",
      "Peso 29: Forma (8, 256)\n",
      "Peso 30: Forma (256, 8, 256)\n",
      "Peso 31: Forma (8, 256)\n",
      "Peso 32: Forma (256, 8, 256)\n",
      "Peso 33: Forma (8, 256)\n",
      "Peso 34: Forma (8, 256, 256)\n",
      "Peso 35: Forma (256,)\n",
      "Peso 36: Forma (256, 2048)\n",
      "Peso 37: Forma (2048,)\n",
      "Peso 38: Forma (2048, 256)\n",
      "Peso 39: Forma (256,)\n",
      "Peso 40: Forma (256,)\n",
      "Peso 41: Forma (256,)\n",
      "Peso 42: Forma (256,)\n",
      "Peso 43: Forma (256,)\n",
      "Peso 44: Forma (256,)\n",
      "Peso 45: Forma (256,)\n",
      "Peso 46: Forma (256, 15000)\n",
      "Peso 47: Forma (15000,)\n"
     ]
    }
   ],
   "source": [
    "# Obtener los pesos\n",
    "weights = transformer.get_weights()  # Esto devuelve una lista con los pesos de cada capa\n",
    "\n",
    "# Puedes ver la estructura de los pesos\n",
    "for i, w in enumerate(weights):\n",
    "    print(f\"Peso {i}: Forma {w.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
       "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,920,434</span> (152.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,920,434\u001b[0m (152.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,218</span> (76.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,960,218\u001b[0m (76.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1500\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = eng_vectorization(eng)\n",
    "    spa = spa_vectorization(spa)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\": spa[:, :-1],\n",
    "        },\n",
    "        spa[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Iniciar el tiempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Callbacks para guardar logs, mejores modelos y evitar sobreentrenamiento\n",
    "csv_logger = CSVLogger(\"training_logs.csv\", append=True)  # Guarda logs en CSV\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"transformer_best.keras\",  # Guarda el mejor modelo\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Detiene si la pérdida no mejora\n",
    "    patience=5,  # Número de épocas sin mejora antes de detener\n",
    "    restore_best_weights=True  # Restaura los mejores pesos encontrados\n",
    ")\n",
    "\n",
    "# 6.a Usar más de 30 épocas\n",
    "new_epochs = 1\n",
    "\n",
    "# 6.c Cambiar la tasa de aprendizaje\n",
    "lr = 1e-4  # Prueba con 1e-3, 5e-4, 1e-5, etc.\n",
    "# 6.d Cambiar el optimizador\n",
    "optimizer = Adam(learning_rate=lr) # probar otros\n",
    "# optimizer = RMSprop(learning_rate=1e-4)\n",
    "\n",
    "transformer.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
    "    metrics=[\"Accuracy\"])\n",
    "\n",
    "\n",
    "# Entrenamiento\n",
    "history = transformer.fit(\n",
    "    train_ds,\n",
    "    epochs=new_epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[csv_logger, checkpoint_callback, early_stopping]\n",
    ")\n",
    "\n",
    "# Guardar modelo completo\n",
    "transformer.save(\"transformer_updated.keras\")\n",
    "\n",
    "# Guardar solo los pesos\n",
    "#transformer.save_weights(\"transformer_weights.h5\")\n",
    "\n",
    "# Medir el tiempo total\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Training completed in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar métricas finales\n",
    "# print(history.history.keys())\n",
    "final_acc = history.history[\"Accuracy\"][-1]\n",
    "final_val_acc = history.history[\"val_Accuracy\"][-1]\n",
    "final_loss = history.history[\"loss\"][-1]\n",
    "final_val_loss = history.history[\"val_loss\"][-1]\n",
    "\n",
    "print(f\"Final Training Accuracy: {final_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"Final Training Loss: {final_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas\n",
    "\n",
    "* 6.e Cambiar las métricas. \n",
    "* 6.f Se BLEU.\n",
    "* 6.g Se utiliza Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk\n",
    "!pip install rouge-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "\n",
    "for test_pair in test_pairs[:10]:\n",
    "    input_sentence = test_pair[0]\n",
    "    reference_sentence = test_pair[1]\n",
    "    translated_sentence = decode_sequence(input_sentence)\n",
    "    translated_sentence = (\n",
    "        translated_sentence.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    scores = rouge_scorer.score(reference_sentence, translated_sentence)\n",
    "    print(f\"Input: {input_sentence}\")\n",
    "    print(f\"Reference: {reference_sentence}\")\n",
    "    print(f\"Translated: {translated_sentence}\")\n",
    "    print(f\"ROUGE-1 Precision: {scores['rouge1'].precision:.4f}, Recall: {scores['rouge1'].recall:.4f}, F1-score: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2 Precision: {scores['rouge2'].precision:.4f}, Recall: {scores['rouge2'].recall:.4f}, F1-score: {scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'scores' is a list of dictionaries, each containing the ROUGE scores for a test pair.\n",
    "# If not, adjust accordingly based on your actual data structure.\n",
    "\n",
    "# Crear una lista de diccionarios para almacenar los resultados\n",
    "rows = []\n",
    "for test_pair in test_pairs[:10]:\n",
    "  input_sentence = test_pair[0]\n",
    "  reference_sentence = test_pair[1]\n",
    "  translated_sentence = decode_sequence(input_sentence)\n",
    "  translated_sentence = (\n",
    "      translated_sentence.replace(\"[PAD]\", \"\")\n",
    "      .replace(\"[START]\", \"\")\n",
    "      .replace(\"[END]\", \"\")\n",
    "      .strip()\n",
    "  )\n",
    "  scores = rouge_scorer.score(reference_sentence, translated_sentence)\n",
    "\n",
    "  row = {\n",
    "      \"Input\": input_sentence,\n",
    "      \"Reference\": reference_sentence,\n",
    "      \"Translated\": translated_sentence,\n",
    "      \"ROUGE-1 Precision\": scores['rouge1'].precision,\n",
    "      \"ROUGE-1 Recall\": scores['rouge1'].recall,\n",
    "      \"ROUGE-1 F1-score\": scores['rouge1'].fmeasure,\n",
    "      \"ROUGE-2 Precision\": scores['rouge2'].precision,\n",
    "      \"ROUGE-2 Recall\": scores['rouge2'].recall,\n",
    "      \"ROUGE-2 F1-score\": scores['rouge2'].fmeasure,\n",
    "  }\n",
    "  rows.append(row)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(\"rouge_scores_II.csv\", index=False)\n",
    "# df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/rouge_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Crear una lista de diccionarios para almacenar los resultados\n",
    "rows = []\n",
    "smoother = SmoothingFunction().method1  # Suavizado para evitar BLEU=0 en frases cortas\n",
    "\n",
    "for test_pair in test_pairs[:10]:\n",
    "    input_sentence = test_pair[0]\n",
    "    reference_sentence = test_pair[1]\n",
    "    translated_sentence = decode_sequence(input_sentence)\n",
    "    translated_sentence = (\n",
    "        translated_sentence.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    # Tokenizar las oraciones\n",
    "    reference_tokens = [reference_sentence.split()]\n",
    "    translated_tokens = translated_sentence.split()\n",
    "\n",
    "    # Calcular BLEU con 1-gram, 2-gram, 3-gram y 4-gram\n",
    "    bleu1 = sentence_bleu(reference_tokens, translated_tokens, weights=(1, 0, 0, 0), smoothing_function=smoother)\n",
    "    bleu2 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoother)\n",
    "    bleu3 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoother)\n",
    "    bleu4 = sentence_bleu(reference_tokens, translated_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoother)\n",
    "\n",
    "    row = {\n",
    "        \"Input\": input_sentence,\n",
    "        \"Reference\": reference_sentence,\n",
    "        \"Translated\": translated_sentence,\n",
    "        \"BLEU-1\": bleu1,\n",
    "        \"BLEU-2\": bleu2,\n",
    "        \"BLEU-3\": bleu3,\n",
    "        \"BLEU-4\": bleu4,\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Crear DataFrame y exportar a CSV\n",
    "df = pd.DataFrame(rows)\n",
    "# df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/bleu_scores.csv\", index=False)\n",
    "df.to_csv(\"bleu_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frase en español\n",
    "ground_truth = \"este es un libro\"\n",
    "# Traducción esperada en inglés (ground truth)\n",
    "sentence = \"this is a book.\"\n",
    "\n",
    "# Convertir a índices\n",
    "encoder_input = eng_vectorization([sentence])  \n",
    "decoder_input = spa_vectorization([ground_truth])[:, :-1]  \n",
    "\n",
    "# Obtener la traducción del modelo\n",
    "translated_text = transformer(\n",
    "    {\n",
    "        \"encoder_inputs\": encoder_input,\n",
    "        \"decoder_inputs\": decoder_input,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Obtener los índices de tokens con mayor probabilidad\n",
    "translated_indices = np.argmax(translated_text.numpy(), axis=-1)[0]  # Seleccionamos la primera oración\n",
    "\n",
    "# Convertir los índices en palabras\n",
    "translated_sentence = \" \".join([spa_vocab[i] for i in translated_indices if i != 0])\n",
    "\n",
    "# Convertir ground truth en una lista de palabras\n",
    "reference = ground_truth.split()\n",
    "candidate = translated_sentence.split()\n",
    "\n",
    "# Calcular BLEU\n",
    "bleu_score = calculate_bleu(reference, candidate)\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = transformer.evaluate(val_ds, verbose=0)\n",
    "print(\"Accuracy: %0.2f%%\" % (scores[1]*100))\n",
    "print(\"test loss, test acc:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K # type: ignore\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "\n",
    "# Obtener las capas del modelo original\n",
    "layer_outputs = [layer.output for layer in transformer.layers]  # Extraer las salidas de cada capa\n",
    "\n",
    "# Definir un nuevo modelo que devuelva las activaciones\n",
    "activation_model = Model(inputs=transformer.input, outputs=layer_outputs)\n",
    "\n",
    "# Verificar la estructura del modelo de activaciones\n",
    "activation_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding test sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_vocab = spa_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    attention_weights = []  # Lista para almacenar los pesos de atención\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
    "\n",
    "        # Assuming your transformer model only returns predictions\n",
    "        predictions = transformer(\n",
    "            {\n",
    "                \"encoder_inputs\": tokenized_input_sentence,\n",
    "                \"decoder_inputs\": tokenized_target_sentence,\n",
    "            }\n",
    "        )\n",
    "        # If you need attention weights, you might need to access them\n",
    "        # from a specific layer in your transformer model or modify its output\n",
    "        # Example: attention_weights_1 = transformer.get_layer('attention_layer_name').output\n",
    "        # Replace 'attention_layer_name' with the actual name of your attention layer\n",
    "\n",
    "        # For now, we'll assign None to attention weights as they aren't returned by the model\n",
    "        attention_weights_1 = None\n",
    "        attention_weights_2 = None\n",
    "\n",
    "        attention_weights.append((attention_weights_1, attention_weights_2))  # Almacenar los pesos de atención\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    return decoded_sentence, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oración de prueba\n",
    "ground_truth = \"este es un libro interesante.\"\n",
    "input_sentence = \"this is an interesting book.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_sentence = \"this is a beautiful tree\"\n",
    "translated_sentence, attention_weights = decode_sequence(input_sentence)\n",
    "print(f\"Translated: {translated_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_attention_head(in_tokens, translated_tokens, attention, ax=None):\n",
    "    \"\"\"Visualiza la atención de una cabeza específica.\"\"\"\n",
    "    translated_tokens = translated_tokens[1:]  # Omite el primer token de salida (start)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Convertir a NumPy antes de graficar\n",
    "    attention = np.array(attention)\n",
    "\n",
    "    # Asegurar que la forma es válida\n",
    "    if attention.ndim != 2:\n",
    "        raise ValueError(f\"Attention data must be 2D, but got shape {attention.shape}\")\n",
    "\n",
    "    cax = ax.matshow(attention, cmap=\"viridis\")\n",
    "\n",
    "    # Etiquetas en los ejes\n",
    "    ax.set_xticks(range(len(in_tokens)))\n",
    "    ax.set_yticks(range(len(translated_tokens)))\n",
    "\n",
    "    # Convertir los tokens a texto si son tensores\n",
    "    if isinstance(in_tokens, tf.Tensor):\n",
    "        in_tokens = in_tokens.numpy()\n",
    "    if isinstance(translated_tokens, tf.Tensor):\n",
    "        translated_tokens = translated_tokens.numpy()\n",
    "\n",
    "    ax.set_xticklabels([label.decode(\"utf-8\") for label in in_tokens.numpy()], rotation=90)\n",
    "    ax.set_yticklabels([label.decode(\"utf-8\") for label in translated_tokens.numpy()])\n",
    "\n",
    "    plt.colorbar(cax)\n",
    "    ax.set_title(\"Mapa de Atención (Cabeza específica)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(sentence, translated_tokens, attention_weights):\n",
    "    \"\"\"Visualiza todas las cabezas de atención.\"\"\"\n",
    "    # Tokenizar la entrada usando el vectorizador de inglés\n",
    "    in_tokens = eng_vectorization([sentence])  # Entrada del codificador (español)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Itera a través de todas las cabezas de atención\n",
    "    for h, head in enumerate(attention_weights):\n",
    "        ax = fig.add_subplot(2, 4, h+1)  # Ajusta la cantidad de subgráficos según el número de cabezas\n",
    "        plot_attention_head(in_tokens, translated_tokens, head, ax)\n",
    "        ax.set_xlabel(f'Head {h+1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(sentence, translated_tokens, attention_weights):\n",
    "    \"\"\"Visualiza todas las cabezas de atención.\"\"\"\n",
    "    in_tokens = eng_vectorization([sentence]).numpy()  # Entrada del codificador (español)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Verificar que `attention_weights` tiene datos\n",
    "    if not isinstance(attention_weights, list) or len(attention_weights) == 0:\n",
    "        print(\"No attention weights available.\")\n",
    "        return\n",
    "\n",
    "    for h, head in enumerate(attention_weights):\n",
    "        if head is None or np.shape(head) == ():\n",
    "            print(f\"Attention head {h} is empty or incorrect.\")\n",
    "            continue  # Saltar esta cabeza si está vacía\n",
    "\n",
    "        ax = fig.add_subplot(2, 4, h + 1)\n",
    "        plot_attention_head(in_tokens, translated_tokens, np.array(head), ax)\n",
    "        ax.set_xlabel(f'Head {h + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducir y obtener los pesos de atención\n",
    "translated_sentence, attention_weights = decode_sequence(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Attention weights type: {type(attention_weights)}\")\n",
    "print(f\"Attention weights shape: {np.shape(attention_weights)}\")\n",
    "print(f\"First attention head shape: {np.shape(attention_weights[0]) if len(attention_weights) > 0 else 'Empty'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los pesos de atención\n",
    "plot_attention_weights(input_sentence, translated_sentence, attention_weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "\n",
    "for test_pair in test_pairs[:5]:\n",
    "    input_sentence = test_pair[0]\n",
    "    reference_sentence = test_pair[1]\n",
    "    translated_sentence = decode_sequence(input_sentence)\n",
    "    translated_sentence = (\n",
    "        translated_sentence.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    scores = rouge_scorer.score(reference_sentence, translated_sentence)\n",
    "    print(f\"Input: {input_sentence}\")\n",
    "    print(f\"Reference: {reference_sentence}\")\n",
    "    print(f\"Translated: {translated_sentence}\")\n",
    "    print(f\"ROUGE-1 Precision: {scores['rouge1'].precision:.4f}, Recall: {scores['rouge1'].recall:.4f}, F1-score: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2 Precision: {scores['rouge2'].precision:.4f}, Recall: {scores['rouge2'].recall:.4f}, F1-score: {scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (tu código anterior para tokenizar y obtener activaciones) ...\n",
    "\n",
    "# Elegir las capas que quieres visualizar\n",
    "layer_indices = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Crear una figura con una subgráfica por capa\n",
    "fig, axes = plt.subplots(len(layer_indices), 1, figsize=(15, 2 * len(layer_indices)))\n",
    "\n",
    "palabras_interes = [\"love\", \"moon\"]  # Palabras de interés\n",
    "\n",
    "for idx, layer_idx in enumerate(layer_indices):\n",
    "    activation_selected = activations[layer_idx]\n",
    "    ax = axes[idx]\n",
    "\n",
    "    if activation_selected.ndim == 1:\n",
    "        ax.plot(activation_selected[0])\n",
    "        ax.set_title(f\"Activación de la capa {transformer.layers[layer_idx].name} (1D)\")\n",
    "    else:\n",
    "        ax.matshow(activation_selected[0], cmap=\"viridis\")\n",
    "        ax.set_title(f\"Activación de la capa {transformer.layers[layer_idx].name} (2D)\")\n",
    "\n",
    "        # Obtener tokens y palabras correspondientes\n",
    "        if layer_idx == 2:  # Capa del encoder\n",
    "            tokens = eng_vectorization.get_vocabulary()\n",
    "            indices = tokenized_encoder_input[0].numpy()\n",
    "            words = [tokens[i] for i in indices if i < len(tokens)]\n",
    "        elif layer_idx == 3:  # Capa del decoder\n",
    "            tokens = spa_vectorization.get_vocabulary()\n",
    "            indices = start_token[0].numpy()\n",
    "            words = [tokens[i] for i in indices if i < len(tokens)]\n",
    "        else:\n",
    "            words = None\n",
    "\n",
    "        if words:\n",
    "            indices_palabras_interes = [i for i, word in enumerate(words) if word in palabras_interes]\n",
    "            if indices_palabras_interes:\n",
    "                ax.set_xticks(np.arange(len(words)))\n",
    "                ax.set_xticklabels(words, rotation=45, ha=\"right\")  # Mostrar palabras en el eje x\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (tu código anterior para tokenizar y obtener activaciones) ...\n",
    "\n",
    "# Elegir las capas que quieres visualizar\n",
    "layer_indices = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Crear una figura con una subgráfica por capa\n",
    "fig, axes = plt.subplots(len(layer_indices), 1, figsize=(15, 2 * len(layer_indices)))\n",
    "\n",
    "for idx, layer_idx in enumerate(layer_indices):\n",
    "    activation_selected = activations[layer_idx]\n",
    "    ax = axes[idx]\n",
    "\n",
    "    if activation_selected.ndim == 1:\n",
    "        ax.plot(activation_selected[0])\n",
    "        ax.set_title(f\"Activación de la capa {transformer.layers[layer_idx].name} (1D)\")\n",
    "    else:\n",
    "        ax.matshow(activation_selected[0], cmap=\"viridis\")\n",
    "        ax.set_title(f\"Activación de la capa {transformer.layers[layer_idx].name} (2D)\")\n",
    "\n",
    "        # Obtener tokens y palabras correspondientes\n",
    "        if layer_idx == 2:  # Capa del encoder\n",
    "            tokens = eng_vectorization.get_vocabulary()\n",
    "            indices = tokenized_encoder_input[0].numpy()\n",
    "            words = [tokens[i] for i in indices if i < len(tokens)]\n",
    "        elif layer_idx == 3:  # Capa del decoder\n",
    "            tokens = spa_vectorization.get_vocabulary()\n",
    "            indices = start_token[0].numpy()\n",
    "            words = [tokens[i] for i in indices if i < len(tokens)]\n",
    "        else:\n",
    "            words = None\n",
    "\n",
    "        if words:\n",
    "            ax.set_xticks(np.arange(len(words)))\n",
    "            ax.set_xticklabels(words, rotation=45, ha=\"right\")  # Mostrar palabras en el eje x\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"training_logs.csv\", usecols=[\"accuracy\", \"loss\"]).head(100)\n",
    "losses = df_results[\"loss\"].values\n",
    "accuracies = df_results[\"accuracy\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "# plot some data\n",
    "ax1.plot(losses, label='loss')\n",
    "#plt.plot(results.history['val_loss'], label='val_loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "# accuracies\n",
    "ax2.plot(accuracies, label='Accuracy')\n",
    "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"training_logs.csv\", usecols=[\"accuracy\", \"loss\"]).iloc[101:]\n",
    "losses = df_results[\"loss\"].values\n",
    "accuracies = df_results[\"accuracy\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "# plot some data\n",
    "ax1.plot(losses, label='loss')\n",
    "#plt.plot(results.history['val_loss'], label='val_loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "# accuracies\n",
    "ax2.plot(accuracies, label='Accuracy')\n",
    "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Martinez_Selene-BhocuyRJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
