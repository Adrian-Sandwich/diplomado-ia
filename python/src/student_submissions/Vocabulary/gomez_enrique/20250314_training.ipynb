{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxcOFuNOXHWQ",
        "outputId": "d47adc08-ad8f-406f-f416-900fc0fbd9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "text_file = '/content/drive/MyDrive/Colab Notebooks/corpus/fr_es_lesmiserables.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bR-9Fa-TXZ-s",
        "outputId": "3aa9915e-3f86-400c-ad33-55f186ffdf26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('eh bien, monsieur le maire voyagera seul et sans bagage afin de ne point charger le cheval.', '[start] pues bien, el señor alcalde viajará solo y sin equipaje para no cargar al caballo. [end]')\n",
            "('dieu merci!', '[start] ¡gracias a dios! [end]')\n",
            "('il chemina ainsi quelque temps, la tête toujours baissée.', '[start] así caminó durante un tiempo, con la cabeza todavía inclinada. [end]')\n",
            "(\"ce sont là de ces combinaisons d'événements dont la vie est pleine.\", '[start] éstas son las combinaciones de eventos de las que está llena la vida. [end]')\n",
            "(\"l'espagne, qui consomme beaucoup de jais noir, y commandait chaque année des achats immenses.\", '[start] españa, que consume mucho azabache, realiza cada año compras enormes de este metal. [end]')\n",
            "7083 total pairs\n",
            "4959 training pairs\n",
            "1062 validation pairs\n",
            "1062 test pairs\n",
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,845,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,259,520\u001b[0m │ positional_embedding_… │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)      │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ transformer_decoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │      \u001b[38;5;34m3,855,000\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embedding_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)      │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "78/78 - 77s - 990ms/step - accuracy: 0.0451 - loss: 7.0289 - val_accuracy: 0.0626 - val_loss: 6.4461\n",
            "Epoch 2/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.0735 - loss: 6.2292 - val_accuracy: 0.0849 - val_loss: 6.0802\n",
            "Epoch 3/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.0886 - loss: 5.8601 - val_accuracy: 0.0873 - val_loss: 5.9128\n",
            "Epoch 4/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.1079 - loss: 5.5404 - val_accuracy: 0.1102 - val_loss: 5.6637\n",
            "Epoch 5/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.1332 - loss: 5.1834 - val_accuracy: 0.1188 - val_loss: 5.5090\n",
            "Epoch 6/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.1646 - loss: 4.7822 - val_accuracy: 0.1481 - val_loss: 5.2677\n",
            "Epoch 7/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.1954 - loss: 4.3962 - val_accuracy: 0.1649 - val_loss: 5.1385\n",
            "Epoch 8/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.2285 - loss: 4.0014 - val_accuracy: 0.1768 - val_loss: 5.0266\n",
            "Epoch 9/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.2588 - loss: 3.6409 - val_accuracy: 0.1890 - val_loss: 4.9120\n",
            "Epoch 10/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.2891 - loss: 3.2728 - val_accuracy: 0.1970 - val_loss: 4.9468\n",
            "Epoch 11/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.3142 - loss: 2.9608 - val_accuracy: 0.1930 - val_loss: 4.9330\n",
            "Epoch 12/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.3373 - loss: 2.6613 - val_accuracy: 0.1987 - val_loss: 4.9570\n",
            "Epoch 13/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.3602 - loss: 2.3931 - val_accuracy: 0.2024 - val_loss: 5.0223\n",
            "Epoch 14/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.3828 - loss: 2.1282 - val_accuracy: 0.2030 - val_loss: 5.0160\n",
            "Epoch 15/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.4053 - loss: 1.8803 - val_accuracy: 0.2122 - val_loss: 5.0137\n",
            "Epoch 16/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.4259 - loss: 1.6547 - val_accuracy: 0.2112 - val_loss: 5.0853\n",
            "Epoch 17/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.4453 - loss: 1.4537 - val_accuracy: 0.2107 - val_loss: 5.2182\n",
            "Epoch 18/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.4632 - loss: 1.2791 - val_accuracy: 0.2093 - val_loss: 5.2256\n",
            "Epoch 19/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.4819 - loss: 1.1102 - val_accuracy: 0.2146 - val_loss: 5.2329\n",
            "Epoch 20/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.4998 - loss: 0.9515 - val_accuracy: 0.2088 - val_loss: 5.4160\n",
            "Epoch 21/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5177 - loss: 0.8082 - val_accuracy: 0.2135 - val_loss: 5.3428\n",
            "Epoch 22/150\n",
            "78/78 - 2s - 25ms/step - accuracy: 0.5315 - loss: 0.6890 - val_accuracy: 0.2147 - val_loss: 5.4179\n",
            "Epoch 23/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5458 - loss: 0.5748 - val_accuracy: 0.2140 - val_loss: 5.5045\n",
            "Epoch 24/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5576 - loss: 0.4819 - val_accuracy: 0.1977 - val_loss: 5.7812\n",
            "Epoch 25/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.5655 - loss: 0.4101 - val_accuracy: 0.2153 - val_loss: 5.6023\n",
            "Epoch 26/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5713 - loss: 0.3565 - val_accuracy: 0.2139 - val_loss: 5.6070\n",
            "Epoch 27/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5764 - loss: 0.3011 - val_accuracy: 0.2147 - val_loss: 5.6555\n",
            "Epoch 28/150\n",
            "78/78 - 2s - 20ms/step - accuracy: 0.5828 - loss: 0.2325 - val_accuracy: 0.2177 - val_loss: 5.7300\n",
            "Epoch 29/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5849 - loss: 0.1995 - val_accuracy: 0.2104 - val_loss: 5.8273\n",
            "Epoch 30/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5884 - loss: 0.1591 - val_accuracy: 0.2107 - val_loss: 5.9245\n",
            "Epoch 31/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5892 - loss: 0.1428 - val_accuracy: 0.2125 - val_loss: 5.9142\n",
            "Epoch 32/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5897 - loss: 0.1300 - val_accuracy: 0.2100 - val_loss: 5.9987\n",
            "Epoch 33/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5906 - loss: 0.1140 - val_accuracy: 0.2088 - val_loss: 6.0451\n",
            "Epoch 34/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5898 - loss: 0.1146 - val_accuracy: 0.2094 - val_loss: 6.0973\n",
            "Epoch 35/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5892 - loss: 0.1214 - val_accuracy: 0.2101 - val_loss: 6.1489\n",
            "Epoch 36/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5905 - loss: 0.1037 - val_accuracy: 0.2137 - val_loss: 6.0990\n",
            "Epoch 37/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5915 - loss: 0.0981 - val_accuracy: 0.2013 - val_loss: 6.2843\n",
            "Epoch 38/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5930 - loss: 0.0820 - val_accuracy: 0.2126 - val_loss: 6.1988\n",
            "Epoch 39/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5936 - loss: 0.0786 - val_accuracy: 0.2118 - val_loss: 6.4521\n",
            "Epoch 40/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5918 - loss: 0.0880 - val_accuracy: 0.2145 - val_loss: 6.3283\n",
            "Epoch 41/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5930 - loss: 0.0779 - val_accuracy: 0.2147 - val_loss: 6.2873\n",
            "Epoch 42/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5929 - loss: 0.0779 - val_accuracy: 0.2105 - val_loss: 6.3688\n",
            "Epoch 43/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5943 - loss: 0.0705 - val_accuracy: 0.2128 - val_loss: 6.4020\n",
            "Epoch 44/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5939 - loss: 0.0729 - val_accuracy: 0.2095 - val_loss: 6.4586\n",
            "Epoch 45/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5944 - loss: 0.0673 - val_accuracy: 0.2127 - val_loss: 6.4301\n",
            "Epoch 46/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5950 - loss: 0.0629 - val_accuracy: 0.2135 - val_loss: 6.5181\n",
            "Epoch 47/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5945 - loss: 0.0684 - val_accuracy: 0.2087 - val_loss: 6.5596\n",
            "Epoch 48/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5950 - loss: 0.0636 - val_accuracy: 0.2116 - val_loss: 6.4962\n",
            "Epoch 49/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5943 - loss: 0.0693 - val_accuracy: 0.2080 - val_loss: 6.4839\n",
            "Epoch 50/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5959 - loss: 0.0563 - val_accuracy: 0.2075 - val_loss: 6.6502\n",
            "Epoch 51/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5956 - loss: 0.0600 - val_accuracy: 0.2104 - val_loss: 6.5744\n",
            "Epoch 52/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5944 - loss: 0.0664 - val_accuracy: 0.2115 - val_loss: 6.5484\n",
            "Epoch 53/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5960 - loss: 0.0549 - val_accuracy: 0.2101 - val_loss: 6.5873\n",
            "Epoch 54/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5969 - loss: 0.0494 - val_accuracy: 0.2116 - val_loss: 6.7072\n",
            "Epoch 55/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5970 - loss: 0.0487 - val_accuracy: 0.2056 - val_loss: 6.6288\n",
            "Epoch 56/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5966 - loss: 0.0500 - val_accuracy: 0.2128 - val_loss: 6.6994\n",
            "Epoch 57/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5967 - loss: 0.0491 - val_accuracy: 0.2136 - val_loss: 6.6608\n",
            "Epoch 58/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5948 - loss: 0.0697 - val_accuracy: 0.2119 - val_loss: 6.6629\n",
            "Epoch 59/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5971 - loss: 0.0452 - val_accuracy: 0.2125 - val_loss: 6.7077\n",
            "Epoch 60/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5975 - loss: 0.0419 - val_accuracy: 0.2116 - val_loss: 6.7127\n",
            "Epoch 61/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5982 - loss: 0.0401 - val_accuracy: 0.2100 - val_loss: 6.7934\n",
            "Epoch 62/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5983 - loss: 0.0375 - val_accuracy: 0.2133 - val_loss: 6.7631\n",
            "Epoch 63/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5974 - loss: 0.0419 - val_accuracy: 0.2097 - val_loss: 6.8117\n",
            "Epoch 64/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5980 - loss: 0.0405 - val_accuracy: 0.2065 - val_loss: 6.7780\n",
            "Epoch 65/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5980 - loss: 0.0378 - val_accuracy: 0.2142 - val_loss: 6.8376\n",
            "Epoch 66/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5978 - loss: 0.0418 - val_accuracy: 0.2116 - val_loss: 6.8156\n",
            "Epoch 67/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5990 - loss: 0.0345 - val_accuracy: 0.2113 - val_loss: 6.7772\n",
            "Epoch 68/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5982 - loss: 0.0385 - val_accuracy: 0.2095 - val_loss: 6.7927\n",
            "Epoch 69/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5992 - loss: 0.0311 - val_accuracy: 0.2151 - val_loss: 6.8350\n",
            "Epoch 70/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5993 - loss: 0.0317 - val_accuracy: 0.2122 - val_loss: 6.8664\n",
            "Epoch 71/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5987 - loss: 0.0359 - val_accuracy: 0.2149 - val_loss: 6.8535\n",
            "Epoch 72/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5985 - loss: 0.0365 - val_accuracy: 0.2136 - val_loss: 6.8855\n",
            "Epoch 73/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5991 - loss: 0.0298 - val_accuracy: 0.2152 - val_loss: 7.0262\n",
            "Epoch 74/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5989 - loss: 0.0330 - val_accuracy: 0.2114 - val_loss: 6.9085\n",
            "Epoch 75/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5982 - loss: 0.0385 - val_accuracy: 0.2125 - val_loss: 7.0227\n",
            "Epoch 76/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5993 - loss: 0.0327 - val_accuracy: 0.2134 - val_loss: 6.9492\n",
            "Epoch 77/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5986 - loss: 0.0373 - val_accuracy: 0.2142 - val_loss: 6.9367\n",
            "Epoch 78/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5985 - loss: 0.0361 - val_accuracy: 0.2163 - val_loss: 6.8754\n",
            "Epoch 79/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5993 - loss: 0.0301 - val_accuracy: 0.2163 - val_loss: 6.9329\n",
            "Epoch 80/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5991 - loss: 0.0313 - val_accuracy: 0.2127 - val_loss: 7.1572\n",
            "Epoch 81/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5997 - loss: 0.0281 - val_accuracy: 0.2116 - val_loss: 6.9970\n",
            "Epoch 82/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5998 - loss: 0.0271 - val_accuracy: 0.2057 - val_loss: 7.1315\n",
            "Epoch 83/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5993 - loss: 0.0302 - val_accuracy: 0.2142 - val_loss: 7.0018\n",
            "Epoch 84/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5992 - loss: 0.0298 - val_accuracy: 0.2073 - val_loss: 7.0519\n",
            "Epoch 85/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5993 - loss: 0.0310 - val_accuracy: 0.2095 - val_loss: 7.0329\n",
            "Epoch 86/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5994 - loss: 0.0302 - val_accuracy: 0.2105 - val_loss: 7.0160\n",
            "Epoch 87/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5990 - loss: 0.0372 - val_accuracy: 0.2061 - val_loss: 7.0434\n",
            "Epoch 88/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6003 - loss: 0.0248 - val_accuracy: 0.2120 - val_loss: 7.0567\n",
            "Epoch 89/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0193 - val_accuracy: 0.2150 - val_loss: 7.0681\n",
            "Epoch 90/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0223 - val_accuracy: 0.2121 - val_loss: 7.0877\n",
            "Epoch 91/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6004 - loss: 0.0227 - val_accuracy: 0.2030 - val_loss: 7.0764\n",
            "Epoch 92/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6006 - loss: 0.0213 - val_accuracy: 0.2099 - val_loss: 7.0011\n",
            "Epoch 93/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6002 - loss: 0.0253 - val_accuracy: 0.2122 - val_loss: 7.0593\n",
            "Epoch 94/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0244 - val_accuracy: 0.2063 - val_loss: 7.0883\n",
            "Epoch 95/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5999 - loss: 0.0277 - val_accuracy: 0.2083 - val_loss: 7.1672\n",
            "Epoch 96/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6000 - loss: 0.0251 - val_accuracy: 0.2139 - val_loss: 7.0999\n",
            "Epoch 97/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0212 - val_accuracy: 0.2122 - val_loss: 7.0841\n",
            "Epoch 98/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0225 - val_accuracy: 0.2099 - val_loss: 7.1020\n",
            "Epoch 99/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6006 - loss: 0.0221 - val_accuracy: 0.2077 - val_loss: 7.1354\n",
            "Epoch 100/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6004 - loss: 0.0212 - val_accuracy: 0.2099 - val_loss: 7.0945\n",
            "Epoch 101/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0216 - val_accuracy: 0.2118 - val_loss: 7.1598\n",
            "Epoch 102/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6002 - loss: 0.0228 - val_accuracy: 0.2062 - val_loss: 7.1790\n",
            "Epoch 103/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0191 - val_accuracy: 0.2076 - val_loss: 7.2493\n",
            "Epoch 104/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5999 - loss: 0.0261 - val_accuracy: 0.2120 - val_loss: 7.0979\n",
            "Epoch 105/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.5995 - loss: 0.0295 - val_accuracy: 0.2104 - val_loss: 7.1110\n",
            "Epoch 106/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6003 - loss: 0.0227 - val_accuracy: 0.2024 - val_loss: 7.2946\n",
            "Epoch 107/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6007 - loss: 0.0211 - val_accuracy: 0.2137 - val_loss: 7.3789\n",
            "Epoch 108/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6009 - loss: 0.0193 - val_accuracy: 0.2123 - val_loss: 7.0682\n",
            "Epoch 109/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6006 - loss: 0.0208 - val_accuracy: 0.2107 - val_loss: 7.1176\n",
            "Epoch 110/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0177 - val_accuracy: 0.2087 - val_loss: 7.2356\n",
            "Epoch 111/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6007 - loss: 0.0210 - val_accuracy: 0.2122 - val_loss: 7.1945\n",
            "Epoch 112/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0211 - val_accuracy: 0.2130 - val_loss: 7.1565\n",
            "Epoch 113/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6007 - loss: 0.0191 - val_accuracy: 0.2134 - val_loss: 7.2146\n",
            "Epoch 114/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6008 - loss: 0.0192 - val_accuracy: 0.2118 - val_loss: 7.2804\n",
            "Epoch 115/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0210 - val_accuracy: 0.2089 - val_loss: 7.2504\n",
            "Epoch 116/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6007 - loss: 0.0198 - val_accuracy: 0.2058 - val_loss: 7.4199\n",
            "Epoch 117/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6011 - loss: 0.0163 - val_accuracy: 0.2125 - val_loss: 7.2540\n",
            "Epoch 118/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0190 - val_accuracy: 0.2096 - val_loss: 7.2541\n",
            "Epoch 119/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6009 - loss: 0.0184 - val_accuracy: 0.2086 - val_loss: 7.3256\n",
            "Epoch 120/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6002 - loss: 0.0254 - val_accuracy: 0.2086 - val_loss: 7.3111\n",
            "Epoch 121/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6011 - loss: 0.0178 - val_accuracy: 0.2067 - val_loss: 7.3510\n",
            "Epoch 122/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6011 - loss: 0.0186 - val_accuracy: 0.2118 - val_loss: 7.2045\n",
            "Epoch 123/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6005 - loss: 0.0217 - val_accuracy: 0.2076 - val_loss: 7.3555\n",
            "Epoch 124/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6011 - loss: 0.0162 - val_accuracy: 0.2084 - val_loss: 7.2847\n",
            "Epoch 125/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0145 - val_accuracy: 0.2119 - val_loss: 7.3584\n",
            "Epoch 126/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6015 - loss: 0.0142 - val_accuracy: 0.2097 - val_loss: 7.2445\n",
            "Epoch 127/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0141 - val_accuracy: 0.2097 - val_loss: 7.3131\n",
            "Epoch 128/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6008 - loss: 0.0190 - val_accuracy: 0.2078 - val_loss: 7.4449\n",
            "Epoch 129/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6009 - loss: 0.0192 - val_accuracy: 0.2039 - val_loss: 7.2892\n",
            "Epoch 130/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0173 - val_accuracy: 0.2102 - val_loss: 7.3378\n",
            "Epoch 131/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6011 - loss: 0.0167 - val_accuracy: 0.2125 - val_loss: 7.3979\n",
            "Epoch 132/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6012 - loss: 0.0179 - val_accuracy: 0.2105 - val_loss: 7.3296\n",
            "Epoch 133/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6010 - loss: 0.0194 - val_accuracy: 0.2090 - val_loss: 7.3577\n",
            "Epoch 134/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6013 - loss: 0.0165 - val_accuracy: 0.2056 - val_loss: 7.2816\n",
            "Epoch 135/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6017 - loss: 0.0134 - val_accuracy: 0.2136 - val_loss: 7.3142\n",
            "Epoch 136/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6015 - loss: 0.0141 - val_accuracy: 0.2050 - val_loss: 7.3494\n",
            "Epoch 137/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0133 - val_accuracy: 0.2099 - val_loss: 7.3738\n",
            "Epoch 138/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6017 - loss: 0.0138 - val_accuracy: 0.2085 - val_loss: 7.3603\n",
            "Epoch 139/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0143 - val_accuracy: 0.2100 - val_loss: 7.3780\n",
            "Epoch 140/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6012 - loss: 0.0158 - val_accuracy: 0.2119 - val_loss: 7.3413\n",
            "Epoch 141/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0135 - val_accuracy: 0.2092 - val_loss: 7.3269\n",
            "Epoch 142/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6014 - loss: 0.0141 - val_accuracy: 0.2114 - val_loss: 7.2989\n",
            "Epoch 143/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6020 - loss: 0.0104 - val_accuracy: 0.2066 - val_loss: 7.3539\n",
            "Epoch 144/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6019 - loss: 0.0119 - val_accuracy: 0.2126 - val_loss: 7.3953\n",
            "Epoch 145/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6016 - loss: 0.0143 - val_accuracy: 0.2105 - val_loss: 7.3550\n",
            "Epoch 146/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6019 - loss: 0.0121 - val_accuracy: 0.2136 - val_loss: 7.3524\n",
            "Epoch 147/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6020 - loss: 0.0114 - val_accuracy: 0.2097 - val_loss: 7.2973\n",
            "Epoch 148/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6021 - loss: 0.0112 - val_accuracy: 0.2129 - val_loss: 7.3174\n",
            "Epoch 149/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6019 - loss: 0.0110 - val_accuracy: 0.2082 - val_loss: 7.4366\n",
            "Epoch 150/150\n",
            "78/78 - 1s - 10ms/step - accuracy: 0.6018 - loss: 0.0131 - val_accuracy: 0.2153 - val_loss: 7.3657\n",
            "l'évêque garda un moment le silence, puis il se tourna brusquement vers le directeur de l'hôpital: monsieur, dit-il, combien pensez-vous qu'il tiendrait de lits rien que dans cette salle?\n",
            "[start] el obispo en un momento entonces se volvió bruscamente volvió hacia el obispo se lo detuvo de repente empezó a\n",
            "\n",
            "la probité, la sincérité, la candeur, la conviction, l'idée du devoir, sont des choses qui, en se trompant, peuvent devenir hideuses, mais qui, même hideuses, restent grandes; leur majesté, propre à la conscience humaine, persiste dans l'horreur.\n",
            "[start] la farmacia del carruaje estaba tan estrechamente la idea de las cosas que son melodías en la marsellesa y se\n",
            "\n",
            "madame magloire, dit l'évêque, vous mettrez des draps blancs au lit de l'alcôve.\n",
            "[start] la señora magloire dijo el obispo se apresuran a la cama de la cama [end]\n",
            "\n",
            "une éventualité laissait même entrevoir, outre le bagne, la peine de mort possible, si l'identité était reconnue et si l'affaire petit-gervais se terminait plus tard par une condamnation.\n",
            "[start] la hebilla dejó de la colonia penal el mismo es que la muerte era tan monstruoso llamado el caso de\n",
            "\n",
            "ce sont là les dangers du dehors, les petits dangers.\n",
            "[start] hay que se llama sus peligros del pequeños [end]\n",
            "\n",
            "un jour il voyait des gens du pays très occupés à arracher des orties.\n",
            "[start] un día vio los gente del país muy antigua procedente del patrullero que pagara [end]\n",
            "\n",
            "au moment où m. l'évêque entra, madame magloire parlait avec quelque vivacité. elle entretenait mademoiselle d'un sujet qui lui était familier et auquel l'évêque était accoutumé. il s'agissait du loquet de la porte d'entrée.\n",
            "[start] en el momento en que el obispo invitaba a madame magloire parecía estudiar con una capa de un tema en\n",
            "\n",
            "dit-il, et cette pauvre femme!\n",
            "[start] dijo esta pobre mujer [end]\n",
            "\n",
            "qui la touche a froid.\n",
            "[start] quién fue arrestado [end]\n",
            "\n",
            "mon frère lui disait tous ces détails avec cette gaîté aisée que vous lui connaissez, entremêlant ses paroles de façons gracieuses pour moi.\n",
            "[start] mi hermano le dijo todos estos detalles del éxtasis de la edad que aún no tendrán cólera esta disposición [end]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import string\n",
        "import re\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "\n",
        "import keras\n",
        "import keras_hub\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Parsing the data\n",
        "\n",
        "Each line contains a French sentence and its corresponding Spanish sentence.\n",
        "The French sentence is the *source sequence* and Spanish one is the *target sequence*.\n",
        "We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence.\n",
        "\"\"\"\n",
        "random.seed(10)\n",
        "\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    fre, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((fre, spa))\n",
        "\n",
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set.\n",
        "\"\"\"\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")\n",
        "\n",
        "\"\"\"\n",
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for French and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The French layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"¿\"` to the set of punctuation characters to be stripped.\n",
        "\"\"\"\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf_strings.lower(input_string)\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "fre_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_fre_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "fre_vectorization.adapt(train_fre_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)\n",
        "\n",
        "\"\"\"\n",
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `decoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def format_dataset(fre, spa):\n",
        "    fre = fre_vectorization(fre)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": fre,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    fre_texts, spa_texts = zip(*pairs)\n",
        "    fre_texts = list(fre_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((fre_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "\"\"\"\n",
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):\n",
        "\"\"\"\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "\n",
        "\"\"\"\n",
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        inputs, encoder_outputs = inputs\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        if mask is None:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
        "        else:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            query_mask=inputs_padding_mask,\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            query_mask=inputs_padding_mask,\n",
        "            key_mask=encoder_outputs_padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Next, we assemble the end-to-end model.\n",
        "\"\"\"\n",
        "\n",
        "embed_dim = 2**8\n",
        "latent_dim = 2**11\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "transformer = keras.Model(\n",
        "   {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
        "   decoder_outputs,\n",
        "   name=\"transformer\",\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs.\n",
        "\"\"\"\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "   \"rmsprop\",\n",
        "   loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
        "   metrics=[\"accuracy\"],\n",
        ")\n",
        "epochs = 150  # This should be at least 30 for convergence\n",
        "\n",
        "# csv logger callback\n",
        "csv_logger = CSVLogger(\"/content/drive/MyDrive/Colab Notebooks/transformer_v4.training.log\")\n",
        "\n",
        "# model checkpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/Colab Notebooks/transformer_v4.checkpoint.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "transformer.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        "    verbose=2,\n",
        "    callbacks=[csv_logger, model_checkpoint],\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new French sentences.\n",
        "We simply feed into the model the vectorized French sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`.\n",
        "\"\"\"\n",
        "\n",
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = fre_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            {\n",
        "                \"encoder_inputs\": tokenized_input_sentence,\n",
        "                \"decoder_inputs\": tokenized_target_sentence,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_fre_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(10):\n",
        "    input_sentence = random.choice(test_fre_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(input_sentence)\n",
        "    print(translated)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUbRsX_kf__p",
        "outputId": "bb1cf2e6-7c90-4f49-f8bc-7b21e399123e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BrM2WzOKs2L-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a695b9-ae66-47cd-ea5e-f12439bfb010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.5193889141082764>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.4420676827430725>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.46071475744247437>}\n",
            "ROUGE-2 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.19125397503376007>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.17053619027137756>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.17445197701454163>}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "## Quantitative evaluation (Rouge metrics)\n",
        "\"\"\"\n",
        "rouge_1 = keras_hub.metrics.RougeN(order=1)\n",
        "rouge_2 = keras_hub.metrics.RougeN(order=2)\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = decode_sequence(input_sentence)\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    rouge_1(reference_sentence, translated_sentence)\n",
        "    rouge_2(reference_sentence, translated_sentence)\n",
        "\n",
        "print(\"ROUGE-1 Score: \", rouge_1.result())\n",
        "print(\"ROUGE-2 Score: \", rouge_2.result())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}