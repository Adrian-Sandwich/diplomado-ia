{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Name = txtProc_BagOfBigrams.ipynb\n",
    "\n",
    "+ Do Txt Processing under Keras TF, specifically, do sentiment analysis using the bag of words approach.\n",
    "\n",
    "+ The IMDB data is used, from \n",
    "\n",
    "```\n",
    "cd ~Data\n",
    "mkdir IMDB\n",
    "cd IMDB\n",
    "in path ~/Data/IMDB :\n",
    "curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "tar -xf aclImdb_v1.tar.gz\n",
    "\n",
    "The commands above create the directory structure \n",
    "aclImdb/\n",
    "...train/\n",
    "......pos/\n",
    "......neg/\n",
    "...test/\n",
    "......pos/\n",
    "......neg/\n",
    "```\n",
    "    \n",
    "+ The data was originally used as part of the paper \"Learning Word Vectors for Sentiment Analysis\" by Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and  Christopher Potts, all from Stanford, 2011.\n",
    "\n",
    "+ The \"readme.txt\" file in the main directory describes the organization of the data files, and the meainig of the names in the files.\n",
    "\n",
    "+ There are 25K text files for training and 25K for testing. The train/pos/ directory contains 12.5k text files, each of which contains positive-sentiment movie reviews Similarly, there are 12.5K negative-sentiment reviews located at the “neg” directory.\n",
    "\n",
    "+ The test/pos and test/neg directories follow the same idea. \n",
    "\n",
    "+ Before creating and running the model, a validation was created (once) by using  5K files from the training set, resulting in a change in size of the training as 25k - 5k = 20k.\n",
    "\n",
    "+ The unsup directory contains \"unsupervised\" data, which is not used.\n",
    "\n",
    "+ The code here uses different vectorization which is different from the code in bag_of_tokens. Here the TextVectorization specifies an additional argument ngrams=2, and it gives a different name to the ngrams produced.\n",
    "\n",
    "+ Once this is done, I think the code flows in the same way as in bag_of_tokens\n",
    "The model contains 16 (dense) layers. The activation function is \"relu\" and uses an input of size max_tokens=20000. \n",
    "\n",
    "+ Once these steps are done the model is created and when it runs, the validation accuracy is 90% so we went from 88% using a bag of tokens to 90% using 2grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version    2.18.0\n",
      "TF Path       /drv3/hm3/code/python/tf2.18/tf2.18/lib/python3.12/site-packages/keras/api/_v2\n",
      "Keras version  3.7.0\n",
      "numpy version  1.26.4\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from logging import logProcesses\n",
    "import os, pathlib, shutil, random\n",
    "from platform import python_branch\n",
    "from syslog import LOG_SYSLOG\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "print(\"TF Version   \", tf.__version__)\n",
    "print(\"TF Path      \", tf.__path__[0])\n",
    "print(\"Keras version \", keras.__version__)\n",
    "print(\"numpy version \", np.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "create_validation_set_fn()\n",
    "\n",
    "Take 20% of the training set for validation. The training set gives away 5k files,\n",
    "therefore after this function executes, the training set will contain 25k-5k=20k.\n",
    "Before running this function it is a good idea to remove the directory (if present).\n",
    "\n",
    "Last time I used this code was with  /drv3/hm3/Data/IMDB/aclImdb/val\n",
    "and its content. \n",
    "\n",
    "DO NOT RUN THIS CODE if the val data is already created\n",
    "\"\"\" \n",
    "def create_validation_set_fn() :\n",
    "  base_dir = pathlib.Path(\"/drv3/hm3/Data/IMDB/aclImdb\")\n",
    "  val_dir = base_dir / \"val\"\n",
    "  train_dir = base_dir / \"train\"\n",
    "\n",
    "  for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1377).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[ -num_val_samples: ]\n",
    "    for fname in val_files :\n",
    "      shutil.move( train_dir / category /fname, val_dir / category / fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_data_sets_fn()\n",
    "\n",
    "trn_ds, tst_ds, val_ds = create_data_sets_fn( strBaseDir )\n",
    "  \n",
    "Rceive a string that contains a base directory where the raw data is stored.\n",
    "Return three data sets, for training, testing and validation\n",
    "  i.e., (trn, tst, val)\n",
    "\"\"\"\n",
    "def create_data_sets_fn( strBaseDir ) :\n",
    "    batch_size = 32\n",
    "    base_dir = pathlib.Path( strBaseDir )\n",
    "    train_ds =  keras.utils.text_dataset_from_directory( base_dir / \"train\", batch_size=batch_size )\n",
    "    val_ds = keras.utils.text_dataset_from_directory( base_dir / \"val\", batch_size=batch_size )\n",
    "    test_ds = keras.utils.text_dataset_from_directory( base_dir / \"test\", batch_size=batch_size )\n",
    "\n",
    "    # verify by printing that the 3 data sets were created correctly\n",
    "    for inputs, targets in train_ds:\n",
    "         print(\"inputs.shape:\", inputs.shape)\n",
    "         print(\"inputs.dtype:\", inputs.dtype)\n",
    "         print(\"targets.shape:\", targets.shape)\n",
    "         print(\"targets.dtype:\", targets.dtype)\n",
    "         print(\"inputs[0]:\", inputs[0])\n",
    "         print(\"targets[0]:\", targets[0])\n",
    "         break\n",
    "    \n",
    "    return train_ds, test_ds, val_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "textvectorization_preprocessing_fn( train_ds, test_ds, val_ds)\n",
    "\n",
    "Get the three data sets as arguments to limit the vocabulary to the 20K\n",
    "most frequent words in the data set. \n",
    "\n",
    "Note that the argument to textVectorization sets the data as bigrams\n",
    "\n",
    " As part of ending, the function returns the items as shown below\n",
    "\n",
    "     return binary_2gram_train_ds, binary_2gram_train_ds, binary_2gram_train_ds\n",
    "\"\"\"\n",
    "def textvectorization_preprocessing_fn( train_ds, test_ds, val_ds ) :\n",
    "  text_vectorization = TextVectorization( ngrams=2, \n",
    "                                         max_tokens=20000, output_mode=\"multi_hot\",)\n",
    "    \n",
    "  # prepare a data set that yields only fields raw text input (no labels)\n",
    "  text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "\n",
    "  text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "  # prepare processed versions for training, validation, testing. Use 8 cores\n",
    "  binary_2gram_train_ds = train_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_2gram_test_ds  = test_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_2gram_val_ds   = val_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "\n",
    "  for inputs, targets in  binary_2gram_train_ds :\n",
    "    print(\"inputs.shape:\",  inputs.shape)\n",
    "    print(\"inputs.dtype:\",  inputs.dtype)\n",
    "    print(\"targets.dtype:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\",     inputs[0])\n",
    "    print(\"targets[0]:\",    targets[0])\n",
    "    break\n",
    "\n",
    "  return binary_2gram_train_ds, binary_2gram_test_ds, binary_2gram_val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_model_fn()\n",
    "get_model_fn( max_tokens=20000, hidden_dim=16)\n",
    "\n",
    "Receive the max number of tokes and the number of layers.\n",
    "Use those parameters to create a dense model of the given dimension.\n",
    "The model's activation is relu      \n",
    "      \n",
    "\"\"\"\n",
    "def get_model_fn( max_tokens=20000, hidden_dim=16) :\n",
    "  inputs = keras.Input(shape=(max_tokens,))\n",
    "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741393068.335800   44679 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9353 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b\"The first one was the best. The second one sucked because the dialog was terrible. Although, the storyline wasn't so bad (in fact, all story lines are good and bad). Throughout the movie, I dosed off a few times. I know that Jackie Chan is a great martial arts expertise, but not a good actor in Rush Hour 2. Chris Tucker, too, wasn't good. And Zhang Ziyi, what can I say, a few lines, terrible acting (But that's based on her script). All the characters there were not that good. But, some of the things I like in Rush Hour 2 is always the action and less sex scenes. I know that Jackie Chan doesn't do those things which is good for him.\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 19:17:55.232280: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.dtype: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m320,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741393078.519227   46116 service.cc:148] XLA service 0x70c8940513b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741393078.519292   46116 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-03-07 19:17:58.540619: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741393078.600573   46116 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 28/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5750 - loss: 0.6779  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741393078.969495   46116 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4747 - val_accuracy: 0.9068 - val_loss: 0.2609\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2598 - val_accuracy: 0.9060 - val_loss: 0.2504\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2273 - val_accuracy: 0.9098 - val_loss: 0.2541\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1887 - val_accuracy: 0.9048 - val_loss: 0.2721\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9410 - loss: 0.1927 - val_accuracy: 0.9062 - val_loss: 0.2807\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1778 - val_accuracy: 0.9002 - val_loss: 0.3029\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.1677 - val_accuracy: 0.8964 - val_loss: 0.3166\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1712 - val_accuracy: 0.8936 - val_loss: 0.3288\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1636 - val_accuracy: 0.8940 - val_loss: 0.3443\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1555 - val_accuracy: 0.8938 - val_loss: 0.3607\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2682\n",
      "Test acc: 0.898\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "      jev_main_fn()\n",
    "\n",
    "Start the execution of the code in this file\n",
    "\n",
    "\"\"\"\n",
    "def jev_main_fn() :\n",
    "  strBaseDir  = \"/drv3/hm3/Data/IMDB/aclImdb\"\n",
    "\n",
    "  # call create_validation_set_fn() once to create 5K files in two directories (pos, neg)\n",
    "  # each with 2.5 k files. The 5K files are taken away from the train set, therefore the\n",
    "  # size of the training set will be 25k - 5k = 20K \n",
    "  #\n",
    "  #  create_validation_set_fn() \n",
    "  #\n",
    "\n",
    "  train_ds, test_ds, val_ds = create_data_sets_fn( strBaseDir )\n",
    "  binary_2gram_train_ds, binary_2gram_test_ds, binary_2gram_val_ds = textvectorization_preprocessing_fn( train_ds, test_ds, val_ds )\n",
    "\n",
    "  model = get_model_fn()\n",
    "  model.summary()\n",
    "  callbacks = [ keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\", save_best_only=True) ]\n",
    "\n",
    "  model.fit(  binary_2gram_train_ds.cache(), \n",
    "              validation_data= binary_2gram_val_ds.cache(),\n",
    "              epochs=10, callbacks=callbacks)\n",
    "  model=keras.models.load_model(\"binary_2gram.keras\")\n",
    "  print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n",
    "\n",
    "  print(\"Done\")\n",
    "\n",
    "#### LET\"S GO ! ! ! ! \n",
    "jev_main_fn()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
